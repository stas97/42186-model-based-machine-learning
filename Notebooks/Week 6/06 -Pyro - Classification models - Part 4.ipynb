{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Classification models  \n",
    "\n",
    "## Part 4: Travel mode choice - Hierarchical models\n",
    "\n",
    "This part is where we start to make things more interesting :-)\n",
    "\n",
    "We will revisit the original real world problem of travel model choice (with 4 classes), but this time we shall consider a hierarchical model. \n",
    "\n",
    "More on that later, for now the same stuff from part 2: imports, loading data, preprocessing, train/test split, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import pystan\n",
    "import pystan_utils\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import config_enumerate, MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "# fix random generator seed (for reproducibility of results)\n",
    "np.random.seed(42)\n",
    "\n",
    "# matplotlib style options\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>individual</th>\n",
       "      <th>hinc</th>\n",
       "      <th>psize</th>\n",
       "      <th>ttme_air</th>\n",
       "      <th>invc_air</th>\n",
       "      <th>invt_air</th>\n",
       "      <th>gc_air</th>\n",
       "      <th>ttme_train</th>\n",
       "      <th>invc_train</th>\n",
       "      <th>invt_train</th>\n",
       "      <th>gc_train</th>\n",
       "      <th>ttme_bus</th>\n",
       "      <th>invc_bus</th>\n",
       "      <th>invt_bus</th>\n",
       "      <th>gc_bus</th>\n",
       "      <th>invc_car</th>\n",
       "      <th>invt_car</th>\n",
       "      <th>gc_car</th>\n",
       "      <th>mode_chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  individual  hinc  psize  ttme_air  invc_air  invt_air  gc_air  \\\n",
       "0           0        70.0  30.0    4.0      10.0      61.0      80.0    73.0   \n",
       "1           1         8.0  15.0    4.0      64.0      48.0     154.0    71.0   \n",
       "2           2        62.0  35.0    2.0      64.0      58.0      74.0    69.0   \n",
       "3           3        61.0  40.0    3.0      45.0      75.0      75.0    96.0   \n",
       "4           4        27.0  70.0    1.0      20.0     106.0     190.0   127.0   \n",
       "\n",
       "   ttme_train  invc_train  invt_train  gc_train  ttme_bus  invc_bus  invt_bus  \\\n",
       "0        44.0        24.0       350.0      77.0      53.0      19.0     395.0   \n",
       "1        55.0        25.0       360.0      80.0      53.0      14.0     462.0   \n",
       "2        30.0        21.0       295.0      66.0      53.0      24.0     389.0   \n",
       "3        44.0        33.0       418.0      96.0      53.0      28.0     463.0   \n",
       "4        34.0        72.0       659.0     143.0      35.0      33.0     653.0   \n",
       "\n",
       "   gc_bus  invc_car  invt_car  gc_car  mode_chosen  \n",
       "0    79.0       4.0     314.0    52.0          1.0  \n",
       "1    84.0       4.0     351.0    57.0          2.0  \n",
       "2    83.0       7.0     315.0    55.0          2.0  \n",
       "3    98.0       5.0     291.0    49.0          1.0  \n",
       "4   104.0      44.0     592.0   108.0          1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv\n",
    "df = pd.read_csv(\"modechoice_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(394, 17)\n",
      "(394,)\n",
      "(394,)\n"
     ]
    }
   ],
   "source": [
    "# separate between features/inputs (X) and target/output variables (y)\n",
    "mat = df.values\n",
    "X = mat[:,2:-1]\n",
    "print(X.shape)\n",
    "y = mat[:,-1].astype(\"int\")\n",
    "print(y.shape)\n",
    "ind = mat[:,1].astype(\"int\")\n",
    "print(ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize input features\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 260\n",
      "num test: 134\n"
     ]
    }
   ],
   "source": [
    "train_perc = 0.66 # percentage of training data\n",
    "split_point = int(train_perc*len(y))\n",
    "perm = np.random.permutation(len(y))\n",
    "ix_train = perm[:split_point]\n",
    "ix_test = perm[split_point:]\n",
    "X_train = X[ix_train,:]\n",
    "X_test = X[ix_test,:]\n",
    "ind_train = ind[ix_train]\n",
    "ind_test = ind[ix_test]\n",
    "y_train = y[ix_train]\n",
    "y_test = y[ix_test]\n",
    "print(\"num train: %d\" % len(y_train))\n",
    "print(\"num test: %d\" % len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline logistic regression model from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [2 2 4 4 4 2 4 1 4 4 4 3 1 4 2 1 4 2 1 4 4 4 4 4 2 4 1 4 1 2 4 4 4 2 3 4 4\n",
      " 3 2 4 4 4 2 2 2 4 1 3 2 3 1 2 4 1 1 4 2 4 4 1 3 2 4 2 4 4 4 3 2 3 2 4 2 4\n",
      " 4 4 1 4 2 2 4 4 1 4 3 4 4 2 1 4 3 1 4 2 1 4 1 4 4 4 1 1 2 1 3 2 4 4 4 4 4\n",
      " 4 4 1 3 3 1 4 3 2 4 1 4 2 1 3 2 2 2 4 4 4 4 2]\n",
      "true values: [4 2 2 4 4 2 1 2 4 4 4 4 1 2 2 1 3 4 1 2 4 3 1 4 2 4 2 1 3 2 4 4 4 4 2 1 1\n",
      " 3 2 1 4 2 2 2 4 1 1 3 2 3 1 2 4 4 1 4 2 4 4 3 3 4 4 4 4 1 1 3 2 1 2 4 2 4\n",
      " 4 4 1 2 4 2 4 4 1 4 3 1 4 4 1 4 3 1 1 2 4 4 4 4 4 1 4 3 3 1 3 2 4 4 4 1 4\n",
      " 4 4 1 4 1 1 4 3 2 1 1 4 2 4 1 2 4 2 1 1 1 4 4]\n",
      "Accuracy: 0.6194029850746269\n"
     ]
    }
   ],
   "source": [
    "# create and fit logistic regression model\n",
    "logreg = linear_model.LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test set\n",
    "y_hat = logreg.predict(X_test)\n",
    "print(\"predictions:\", y_hat)\n",
    "print(\"true values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical logistic regression in STAN\n",
    "\n",
    "We will now implement a hierarchical logistic regression. The motivation is actually quite simple. Our dataset consists of multiple observations from various individuals. However, when we build our original logistic regression in STAN, our specification assumes that all individuals share a unique set of bias (alpha) coefficients (beta). In other words, this is equivalent to assuming, for example, that all individuals are equally biased towards a given mode (e.g. car). This is obviously a very strong assumption, right? We should allow different individuals to have different biases (alpha). (We could also consider different coefficients per individual, but for the sake of simplicy, we will just focus on the bias parameters)\n",
    "\n",
    "This can be done by placing a hierarchical prior on the intercepts (alpha). The generative process then becomes:\n",
    "\n",
    "1. For each class $c \\in \\{1,\\dots,C\\}$\n",
    "    2. Draw global intercept mean $\\mu_c \\sim \\mathcal{N}(0,10)$\n",
    "    3. Draw global intercept variance $\\sigma_c \\sim \\mbox{Cauchy}(0,10)$\n",
    "    5. Draw coefficients $\\boldsymbol\\beta_c \\sim \\mathcal{N}(\\textbf{0},10 \\, \\textbf{I})$ (this the same as before...)\n",
    "    6. For each individual $i \\in \\{1,\\dots,I\\}$\n",
    "        4. Draw $\\alpha_{i,c}$ such that $\\alpha_{i,c} \\sim \\mathcal{N}(\\mu_c,\\sigma_c)$\n",
    "\n",
    "6. For each data point $n=\\{1,\\dots,N\\}$\n",
    "    7. Draw target class $y_n \\sim \\mbox{Multinomial}(\\mbox{Softmax}(\\textbf{x}_n,\\boldsymbol\\alpha_{i_n},\\boldsymbol\\beta_1,\\dots,\\boldsymbol\\beta_C))$\n",
    "    \n",
    "where $i_n$ is the individual identifier for person $n$, and $\\boldsymbol\\mu=\\{\\mu_1\\dots\\mu_C\\}$ and $\\boldsymbol\\sigma=\\{\\sigma_1\\dots\\sigma_C\\}$.\n",
    "\n",
    "Notice that now, instead of a single intercept per class $\\alpha_c$ for all individual, we now have a vector of intercepts $\\boldsymbol\\alpha_c$ for each class $c$: one intercept parameter per individual! However, all these intercept share a global (population-level) prior.\n",
    "\n",
    "Lets try to implement this in STAN. Can you do it? :-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_f8c029f9b59592cf5c4adefff4128296 NOW.\n"
     ]
    }
   ],
   "source": [
    "# define Stan model\n",
    "model_definition = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;      // shape of data\n",
    "  int<lower=0> D;      // dimensions of x\n",
    "  int<lower=0> C;      // number of possible choices\n",
    "  int<lower=0> I;      //\n",
    "  int          ind[N]; //\n",
    "  matrix[N,D]  X;      // feature matrix\n",
    "  int          y[N];   // response vector\n",
    "}\n",
    "parameters {\n",
    "  vector[C]     mu_prior;       // global intercept mean \n",
    "  real<lower=0> sigma_prior[C]; // global intercept sd \n",
    "  matrix[C,I]   alpha;          // intercept  \n",
    "  matrix[C,D]   beta;           // parameters\n",
    "}\n",
    "model{\n",
    "\n",
    "  // choice parameters\n",
    "  for (c in 1:C){          \n",
    "    mu_prior[c]    ~ normal(0,5);\n",
    "    sigma_prior[c] ~ cauchy(0,5);\n",
    "    beta[c]        ~ normal(0,10);\n",
    "    \n",
    "    // individual parameters (for each class)\n",
    "    for (i in 1:I){        \n",
    "      alpha[c,i]   ~ normal(mu_prior[c], sigma_prior[c]);\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  for (n in 1:N){\n",
    "    y[n] ~ categorical_logit(alpha[,ind[n]] + beta*X[n]');\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# compile model\n",
    "sm = pystan.StanModel(model_code=model_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_model(X, n_cat, obs=None):\n",
    "    n_beta = X.shape[1]\n",
    "    alpha_mean = pyro.sample(\"alpha_mean\", dist.Normal(0., 5.).expand([n_cat]).to_event(1))  # Prior for the bias mean\n",
    "    alpha_std  = pyro.sample(\"alpha_std\",  dist.HalfCauchy(5.).expand([n_cat]).to_event(1))  # Prior for the bias standard deviation\n",
    "    beta  = pyro.sample(\"beta\", dist.Normal(0., 5.).expand([n_beta, n_cat]).to_event(1))     # Priors for the regression coefficents\n",
    "    \n",
    "    mu = X.matmul(beta)\n",
    "    with pyro.plate(\"data\", X.shape[0]):\n",
    "        alpha = pyro.sample(\"alpha\", dist.Normal(alpha_mean, alpha_std).to_event(1)) # Draw the individual parameter for each individual\n",
    "        y = pyro.sample(\"y\", dist.Categorical(logits=alpha+mu), obs=obs) # If you use logits you don't need to do sigmoid\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cat = 4\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input data for STAN, compile STAN program and run inference using ADVI (much faster in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [24:18,  1.33s/it, step size=2.79e-02, acc. prob=0.893]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(hierarchical_model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=100, num_chains=1)\n",
    "mcmc.run(X_train, n_cat, y_train-1) # Pyro accepts categories starting from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "alpha_mean[0]      0.33      3.07      0.71     -4.81      5.95     10.24      1.10\n",
      "alpha_mean[1]      0.71      2.71      0.66     -2.73      6.04      7.31      1.03\n",
      "alpha_mean[2]     -2.73      3.03     -2.74     -7.70      2.16      8.10      1.01\n",
      "alpha_mean[3]     -1.78      3.31     -1.73     -7.39      3.63     68.48      1.00\n",
      " alpha_std[0]      3.92      2.59      3.83      0.33      7.80      7.28      1.04\n",
      " alpha_std[1]      1.55      0.96      1.22      0.36      2.68      6.07      1.05\n",
      " alpha_std[2]      2.25      1.50      2.09      0.37      3.90      9.29      1.12\n",
      " alpha_std[3]     38.78     11.78     38.74     16.78     55.16     13.99      1.07\n",
      "    beta[0,0]      0.89      2.89      0.87     -3.90      5.50    423.08      1.00\n",
      "    beta[0,1]     -4.27      3.01     -4.18     -9.23      0.82    348.90      1.00\n",
      "    beta[0,2]     -0.45      2.90     -0.43     -5.75      3.74   1126.64      1.00\n",
      "    beta[0,3]      4.51      3.43      4.53     -1.56      9.77   1062.93      1.00\n",
      "    beta[1,0]     -2.76      3.02     -2.58     -7.99      1.98    864.34      1.00\n",
      "    beta[1,1]      1.26      3.05      1.38     -3.76      6.18   1067.44      1.00\n",
      "    beta[1,2]     -0.66      3.16     -0.57     -5.85      4.64    720.39      1.00\n",
      "    beta[1,3]      1.91      3.67      1.85     -4.28      7.61    851.99      1.00\n",
      "    beta[2,0]     -4.42      2.85     -4.42     -9.32     -0.18    111.41      1.00\n",
      "    beta[2,1]      0.98      2.97      0.98     -3.55      6.26    285.38      1.00\n",
      "    beta[2,2]     -0.87      2.85     -0.78     -5.35      3.62    984.32      1.00\n",
      "    beta[2,3]      4.05      3.53      3.90     -2.03      9.81    689.75      1.00\n",
      "    beta[3,0]      0.84      3.74      0.86     -6.02      6.00    295.82      1.00\n",
      "    beta[3,1]     -0.81      4.06     -0.61     -7.94      5.26   1124.27      1.00\n",
      "    beta[3,2]     -0.42      3.83     -0.36     -6.20      6.11    630.10      1.00\n",
      "    beta[3,3]      0.04      4.29      0.16     -7.59      6.64    530.10      1.00\n",
      "    beta[4,0]     -3.12      3.06     -3.15     -8.53      1.69    282.13      1.00\n",
      "    beta[4,1]      0.28      3.01      0.23     -4.51      5.38    766.45      1.00\n",
      "    beta[4,2]      0.97      2.95      0.94     -3.76      5.63   1008.44      1.00\n",
      "    beta[4,3]      1.82      3.72      1.78     -4.41      7.34    993.11      1.00\n",
      "    beta[5,0]      3.15      3.78      3.24     -2.95      9.31    943.90      1.00\n",
      "    beta[5,1]     -2.17      4.04     -2.20     -8.79      4.14    972.89      1.00\n",
      "    beta[5,2]      0.22      4.15      0.27     -6.45      6.97    939.67      1.00\n",
      "    beta[5,3]     -1.12      4.64     -1.15     -8.87      5.98    950.99      1.00\n",
      "    beta[6,0]      2.34      2.86      2.37     -2.30      7.05    239.45      1.01\n",
      "    beta[6,1]     -2.99      2.73     -3.03     -7.42      1.32    195.60      1.00\n",
      "    beta[6,2]     -0.96      2.95     -1.12     -5.20      4.26   1161.32      1.00\n",
      "    beta[6,3]      1.82      3.60      1.81     -4.40      7.14    301.65      1.01\n",
      "    beta[7,0]      1.79      3.53      1.71     -4.28      7.27    205.95      1.00\n",
      "    beta[7,1]     -0.66      3.45     -0.55     -6.62      4.38    210.93      1.00\n",
      "    beta[7,2]     -0.22      3.71     -0.20     -5.93      5.91    726.53      1.00\n",
      "    beta[7,3]     -0.87      4.07     -0.81     -7.55      5.69    656.01      1.00\n",
      "    beta[8,0]     -0.07      3.94     -0.08     -6.39      6.61    784.78      1.00\n",
      "    beta[8,1]    -12.04      3.95    -11.98    -18.34     -5.69    942.74      1.00\n",
      "    beta[8,2]      6.71      4.27      6.70     -0.19     13.82    987.11      1.00\n",
      "    beta[8,3]      5.40      4.79      5.28     -1.98     13.68    410.05      1.00\n",
      "    beta[9,0]      3.61      4.22      3.65     -3.37     10.43   1179.89      1.00\n",
      "    beta[9,1]     -7.45      4.31     -7.62    -14.93     -0.46    762.69      1.00\n",
      "    beta[9,2]      3.41      4.13      3.49     -3.87     10.03   1209.62      1.00\n",
      "    beta[9,3]      0.83      4.61      0.86     -6.89      7.88   1018.28      1.00\n",
      "   beta[10,0]      1.90      2.93      1.95     -3.61      6.11    689.14      1.00\n",
      "   beta[10,1]      1.81      3.08      1.78     -3.21      6.66    978.01      1.00\n",
      "   beta[10,2]     -5.45      2.88     -5.36     -9.42      0.06    917.91      1.00\n",
      "   beta[10,3]      1.96      3.73      1.84     -4.06      7.90    843.70      1.00\n",
      "   beta[11,0]     -0.84      3.26     -0.75     -5.65      4.79    852.08      1.00\n",
      "   beta[11,1]      3.88      3.36      3.87     -1.96      9.09    559.05      1.01\n",
      "   beta[11,2]     -1.24      3.41     -1.26     -6.67      4.08   1037.79      1.00\n",
      "   beta[11,3]     -1.40      4.29     -1.39     -8.44      5.98    714.76      1.00\n",
      "   beta[12,0]     -0.41      4.04     -0.33     -7.02      6.20    570.92      1.00\n",
      "   beta[12,1]      5.79      4.30      5.87     -1.22     12.62   1365.91      1.00\n",
      "   beta[12,2]     -9.69      3.97     -9.61    -15.55     -2.62    943.74      1.00\n",
      "   beta[12,3]      3.74      4.34      3.63     -3.90     10.36    807.95      1.00\n",
      "   beta[13,0]      0.44      3.95      0.46     -6.25      6.63    745.30      1.00\n",
      "   beta[13,1]      4.21      4.09      4.17     -2.01     11.36   1226.42      1.00\n",
      "   beta[13,2]     -3.69      4.27     -3.69     -9.79      4.13   1018.31      1.00\n",
      "   beta[13,3]     -0.81      4.61     -0.72     -8.67      6.95    929.26      1.00\n",
      "   beta[14,0]      3.07      3.33      2.95     -1.94      8.98   1149.79      1.00\n",
      "   beta[14,1]      0.82      3.34      0.80     -5.16      5.99   1005.05      1.00\n",
      "   beta[14,2]     -2.65      3.34     -2.66     -8.03      2.92    850.91      1.00\n",
      "   beta[14,3]     -1.36      3.94     -1.29     -8.40      4.64   1113.15      1.00\n",
      "   beta[15,0]     -5.27      4.12     -5.22    -11.82      1.75   1197.23      1.00\n",
      "   beta[15,1]      4.46      3.96      4.40     -1.97     10.49   1187.64      1.00\n",
      "   beta[15,2]      4.19      4.13      4.32     -2.25     11.05    830.76      1.00\n",
      "   beta[15,3]     -3.62      4.51     -3.66    -10.84      3.77   1125.45      1.00\n",
      "   beta[16,0]     -1.23      4.25     -1.37     -8.32      5.33   1133.16      1.00\n",
      "   beta[16,1]      4.00      4.07      4.06     -2.98     10.35   1240.50      1.00\n",
      "   beta[16,2]      2.77      4.16      2.63     -4.24      9.35   1015.95      1.01\n",
      "   beta[16,3]     -5.30      4.28     -5.29    -12.60      1.27   1142.58      1.00\n",
      "   alpha[0,0]      0.34      5.19      0.48     -8.10      9.55     39.26      1.02\n",
      "   alpha[0,1]      0.63      3.08      0.30     -3.98      6.14     10.45      1.03\n",
      "   alpha[0,2]     -2.52      3.82     -2.46     -9.08      3.15     13.89      1.01\n",
      "   alpha[0,3]    -17.95     30.46    -12.81    -71.05     25.17    525.59      1.00\n",
      "   alpha[1,0]      0.76      5.46      0.73     -7.58     10.07     39.25      1.02\n",
      "   alpha[1,1]      0.67      3.17      0.35     -4.81      5.78     10.80      1.02\n",
      "   alpha[1,2]     -2.63      4.10     -2.31     -9.52      3.17     16.26      1.00\n",
      "   alpha[1,3]    -21.59     31.16    -15.85    -71.42     25.28    174.09      1.03\n",
      "   alpha[2,0]      0.05      5.35      0.28     -9.57      8.10     35.82      1.03\n",
      "   alpha[2,1]      0.64      3.32      0.51     -4.44      6.29     12.80      1.01\n",
      "   alpha[2,2]     -2.73      3.90     -2.52     -9.91      2.93     14.72      1.00\n",
      "   alpha[2,3]    -20.50     29.31    -14.97    -63.68     19.86    434.90      1.01\n",
      "   alpha[3,0]      1.06      5.26      0.70     -6.58      9.71     26.92      1.03\n",
      "   alpha[3,1]      0.64      3.26      0.29     -3.75      6.53     11.93      1.02\n",
      "   alpha[3,2]     -2.76      4.22     -2.52     -8.98      4.11     17.35      1.01\n",
      "   alpha[3,3]    -26.71     28.26    -21.18    -69.38     13.47    251.26      1.01\n",
      "   alpha[4,0]      0.56      5.69      0.76     -8.23      9.27     87.61      1.02\n",
      "   alpha[4,1]      0.71      3.32      0.46     -4.15      6.76     11.82      1.02\n",
      "   alpha[4,2]     -2.78      4.14     -2.57     -9.52      3.41     18.31      1.01\n",
      "   alpha[4,3]     -8.27     36.34     -6.41    -68.72     47.28    722.03      1.00\n",
      "   alpha[5,0]     -0.18      5.35      0.07     -8.54      8.28     39.05      1.04\n",
      "   alpha[5,1]      0.96      3.44      0.52     -3.47      7.77      9.75      1.03\n",
      "   alpha[5,2]     -2.88      4.21     -2.58     -8.71      4.00     18.36      1.00\n",
      "   alpha[5,3]    -35.96     28.12    -31.58    -76.59      8.10     78.05      1.01\n",
      "   alpha[6,0]      0.07      5.93      0.41     -7.34     11.66     23.35      1.04\n",
      "   alpha[6,1]      0.81      3.28      0.42     -4.41      6.55      9.46      1.03\n",
      "   alpha[6,2]     -2.87      4.21     -2.64     -9.66      2.89     15.07      1.01\n",
      "   alpha[6,3]    -27.27     28.65    -21.52    -70.34     14.55    263.05      1.00\n",
      "   alpha[7,0]      0.11      5.42      0.17     -7.05     10.48     47.61      1.02\n",
      "   alpha[7,1]      0.75      3.34      0.39     -4.31      6.94     11.20      1.02\n",
      "   alpha[7,2]     -2.83      4.15     -2.50     -9.68      3.00     17.99      1.01\n",
      "   alpha[7,3]     19.28     30.55     12.60    -21.28     67.03    107.68      1.01\n",
      "   alpha[8,0]      0.28      5.89      0.30     -9.29     10.63     51.86      1.02\n",
      "   alpha[8,1]      0.67      3.12      0.41     -3.80      6.58     10.89      1.02\n",
      "   alpha[8,2]     -2.96      3.96     -2.52     -9.11      3.47     12.73      1.00\n",
      "   alpha[8,3]     31.57     24.32     25.86     -2.98     66.58     67.57      1.01\n",
      "   alpha[9,0]      0.58      5.66      0.47     -7.99     10.16     39.33      1.03\n",
      "   alpha[9,1]      0.79      3.21      0.57     -4.34      6.00     10.27      1.01\n",
      "   alpha[9,2]     -2.58      4.27     -2.50    -10.70      2.85     17.38      1.01\n",
      "   alpha[9,3]    -21.37     31.71    -16.13    -72.75     23.04    256.09      1.01\n",
      "  alpha[10,0]      0.53      5.39      0.62     -7.98      9.45     45.32      1.02\n",
      "  alpha[10,1]      0.77      3.21      0.38     -4.27      6.32      9.28      1.04\n",
      "  alpha[10,2]     -2.80      4.12     -2.43     -9.75      3.64     15.58      1.00\n",
      "  alpha[10,3]     20.24     28.32     15.52    -19.13     65.40    161.15      1.01\n",
      "  alpha[11,0]      0.56      5.54      0.77     -7.06      9.58     43.65      1.02\n",
      "  alpha[11,1]      0.79      3.27      0.49     -4.73      5.99     10.18      1.02\n",
      "  alpha[11,2]     -2.81      3.79     -2.59     -8.98      3.57     15.87      1.00\n",
      "  alpha[11,3]    -24.25     29.77    -18.83    -71.25     17.09    388.59      1.00\n",
      "  alpha[12,0]     -2.74      5.22     -1.61    -12.23      3.96     20.53      1.06\n",
      "  alpha[12,1]      0.34      3.04      0.25     -4.16      5.45     16.67      1.01\n",
      "  alpha[12,2]     -0.71      4.02     -0.93     -7.74      5.44     17.00      1.03\n",
      "  alpha[12,3]    -30.45     26.91    -25.23    -67.11      9.07    243.06      1.01\n",
      "  alpha[13,0]      0.77      5.94      0.52     -7.47     12.96     35.06      1.03\n",
      "  alpha[13,1]      0.76      3.25      0.48     -4.11      6.45     11.71      1.02\n",
      "  alpha[13,2]     -2.85      4.21     -2.55     -9.96      3.60     16.60      1.00\n",
      "  alpha[13,3]    -18.93     30.96    -14.76    -66.39     26.91    489.98      1.01\n",
      "  alpha[14,0]     -0.51      5.19     -0.06     -8.59      8.33     25.96      1.06\n",
      "  alpha[14,1]      1.16      3.60      0.56     -3.53      8.21      8.78      1.03\n",
      "  alpha[14,2]     -3.28      3.98     -3.03     -9.66      2.43     11.68      1.00\n",
      "  alpha[14,3]    -28.52     30.24    -22.24    -71.48     17.00    232.78      1.00\n",
      "  alpha[15,0]     -0.12      5.98      0.18     -8.71     10.40     27.21      1.05\n",
      "  alpha[15,1]      0.58      3.18      0.39     -5.53      5.06     12.03      1.02\n",
      "  alpha[15,2]     -2.69      4.23     -2.52     -8.60      4.53     15.88      1.01\n",
      "  alpha[15,3]     32.17     27.72     26.71     -7.33     73.11    117.90      1.01\n",
      "  alpha[16,0]      0.38      5.47      0.34     -9.23      8.88     45.93      1.02\n",
      "  alpha[16,1]      0.72      3.18      0.53     -3.83      6.67      9.91      1.03\n",
      "  alpha[16,2]     -2.84      4.07     -2.49     -9.51      3.20     16.50      1.01\n",
      "  alpha[16,3]     22.85     29.50     17.26    -18.87     65.52    274.53      1.00\n",
      "  alpha[17,0]      0.39      5.27      0.42     -8.13      9.16     43.36      1.02\n",
      "  alpha[17,1]      0.77      3.28      0.44     -3.67      7.45     10.72      1.03\n",
      "  alpha[17,2]     -2.96      4.23     -2.72     -9.45      3.56     12.83      1.01\n",
      "  alpha[17,3]    -20.82     28.14    -16.46    -61.99     23.77    361.02      1.00\n",
      "  alpha[18,0]      0.11      6.15      0.28     -8.42     11.61     32.94      1.03\n",
      "  alpha[18,1]      0.73      3.23      0.44     -4.16      6.50     10.57      1.02\n",
      "  alpha[18,2]     -2.83      3.99     -2.70     -9.59      3.18     15.19      1.00\n",
      "  alpha[18,3]    -11.77     31.93     -7.02    -60.94     37.21    447.37      1.00\n",
      "  alpha[19,0]     -0.26      6.37      0.19     -7.17     10.12     27.68      1.04\n",
      "  alpha[19,1]      0.70      3.17      0.42     -3.49      6.89     10.93      1.02\n",
      "  alpha[19,2]     -2.57      3.97     -2.52     -8.78      4.49     14.75      1.00\n",
      "  alpha[19,3]    -21.95     30.70    -15.69    -70.96     19.57    299.66      1.00\n",
      "  alpha[20,0]     -2.14      4.71     -1.33     -9.47      5.49     23.76      1.05\n",
      "  alpha[20,1]      1.78      3.68      1.24     -3.28      9.08      7.38      1.05\n",
      "  alpha[20,2]     -3.71      4.03     -3.24    -10.59      1.96     10.25      1.00\n",
      "  alpha[20,3]    -41.97     26.55    -34.86    -82.30     -3.84     95.78      1.03\n",
      "  alpha[21,0]     -0.03      5.13      0.17     -9.11      8.10     34.86      1.04\n",
      "  alpha[21,1]      0.73      3.21      0.53     -4.17      6.29     10.89      1.02\n",
      "  alpha[21,2]     -2.64      4.09     -2.47     -9.31      4.09     15.03      1.01\n",
      "  alpha[21,3]     28.83     27.72     22.16     -8.11     69.72    108.32      1.00\n",
      "  alpha[22,0]      1.04      5.15      0.74     -6.65      9.82     24.51      1.03\n",
      "  alpha[22,1]      0.71      3.31      0.53     -4.97      6.08     10.12      1.03\n",
      "  alpha[22,2]     -2.83      3.97     -2.65     -9.09      3.51     14.02      1.01\n",
      "  alpha[22,3]    -26.26     30.46    -19.56    -70.98     14.34    222.68      1.01\n",
      "  alpha[23,0]      1.22      5.44      0.77     -6.93     10.34     20.74      1.04\n",
      "  alpha[23,1]      0.66      3.27      0.50     -4.93      5.85     11.18      1.02\n",
      "  alpha[23,2]     -2.86      3.77     -2.50     -9.50      2.59     13.06      1.00\n",
      "  alpha[23,3]    -24.29     31.71    -17.83    -71.79     22.31    384.67      1.00\n",
      "  alpha[24,0]      0.36      5.84      0.44     -8.33     10.74     50.99      1.02\n",
      "  alpha[24,1]      0.70      3.40      0.29     -4.83      6.22     11.56      1.02\n",
      "  alpha[24,2]     -2.56      4.02     -2.42     -9.54      3.09     15.53      1.00\n",
      "  alpha[24,3]    -23.69     32.87    -17.34    -73.96     22.09    370.70      1.00\n",
      "  alpha[25,0]      0.95      5.15      0.85     -6.05     10.94     35.94      1.02\n",
      "  alpha[25,1]      0.82      3.21      0.59     -3.88      6.49      9.73      1.02\n",
      "  alpha[25,2]     -3.04      4.18     -2.63     -9.20      3.64     16.07      1.00\n",
      "  alpha[25,3]    -20.99     31.81    -14.15    -65.58     28.94    232.64      1.01\n",
      "  alpha[26,0]      0.12      5.75      0.34    -10.91      8.82     29.77      1.04\n",
      "  alpha[26,1]      0.75      3.33      0.36     -3.97      6.74     10.96      1.03\n",
      "  alpha[26,2]     -2.48      4.05     -2.37     -8.69      3.85     15.72      1.01\n",
      "  alpha[26,3]    -26.88     27.91    -21.66    -70.39     14.75    187.88      1.01\n",
      "  alpha[27,0]      0.02      5.44      0.25     -7.91     10.42     58.04      1.02\n",
      "  alpha[27,1]      0.74      3.39      0.42     -4.98      6.19     11.57      1.03\n",
      "  alpha[27,2]     -2.72      4.10     -2.54     -9.39      3.25     14.96      1.00\n",
      "  alpha[27,3]     27.63     29.06     22.70    -11.25     72.40    120.94      1.01\n",
      "  alpha[28,0]      0.30      5.63      0.33     -7.39     10.87     35.03      1.04\n",
      "  alpha[28,1]      0.73      3.28      0.51     -4.11      6.65     11.09      1.02\n",
      "  alpha[28,2]     -2.77      3.78     -2.66     -8.83      3.52     13.31      1.00\n",
      "  alpha[28,3]     25.72     27.04     22.21    -19.02     65.35    266.77      1.00\n",
      "  alpha[29,0]      0.03      5.47      0.40     -7.36     10.54     29.50      1.05\n",
      "  alpha[29,1]      0.74      3.21      0.49     -4.94      6.02     11.00      1.02\n",
      "  alpha[29,2]     -2.47      3.99     -2.43     -8.78      3.77     15.72      1.01\n",
      "  alpha[29,3]    -17.44     30.93    -11.33    -67.87     27.04    614.55      1.01\n",
      "  alpha[30,0]      0.10      5.41      0.32     -9.78      7.47     53.07      1.02\n",
      "  alpha[30,1]      0.89      3.34      0.62     -4.93      6.26     10.14      1.02\n",
      "  alpha[30,2]     -2.68      3.93     -2.53     -9.27      3.11     13.55      1.01\n",
      "  alpha[30,3]    -13.70     33.52     -9.44    -72.07     33.88    508.61      1.00\n",
      "  alpha[31,0]      0.35      5.78      0.25     -8.27     10.46     32.99      1.04\n",
      "  alpha[31,1]      0.84      3.36      0.46     -3.79      7.21     10.47      1.03\n",
      "  alpha[31,2]     -2.85      3.89     -2.51     -9.40      3.13     12.11      1.00\n",
      "  alpha[31,3]     21.09     28.97     15.06    -22.28     63.31    249.15      1.01\n",
      "  alpha[32,0]      3.95      5.31      2.79     -3.41     13.25     11.32      1.00\n",
      "  alpha[32,1]      0.19      3.07     -0.09     -4.08      5.84     13.96      1.02\n",
      "  alpha[32,2]     -2.85      4.00     -2.71     -9.18      3.39     13.44      1.01\n",
      "  alpha[32,3]    -21.11     31.22    -14.44    -71.10     23.58    282.62      1.01\n",
      "  alpha[33,0]      0.19      5.35      0.38     -9.15      9.28     30.40      1.04\n",
      "  alpha[33,1]      0.76      3.31      0.46     -4.80      5.93     11.22      1.03\n",
      "  alpha[33,2]     -2.75      3.88     -2.51     -8.65      4.01     16.15      1.00\n",
      "  alpha[33,3]    -26.07     28.64    -20.50    -69.22     14.12    181.71      1.01\n",
      "  alpha[34,0]      1.85      5.23      1.13     -5.48     11.73     23.25      1.02\n",
      "  alpha[34,1]      0.72      3.14      0.42     -4.34      6.04     10.07      1.03\n",
      "  alpha[34,2]     -3.08      4.10     -2.70    -10.32      2.88     13.03      1.00\n",
      "  alpha[34,3]    -28.24     28.38    -21.54    -73.83     10.32    220.48      1.01\n",
      "  alpha[35,0]     -0.39      5.32      0.22    -10.10      7.35     33.56      1.04\n",
      "  alpha[35,1]      0.96      3.42      0.53     -4.29      6.77      9.43      1.03\n",
      "  alpha[35,2]     -2.79      4.07     -2.65     -9.33      3.43     13.26      1.01\n",
      "  alpha[35,3]    -33.40     29.02    -26.49    -74.48      5.61     95.14      1.01\n",
      "  alpha[36,0]      3.05      5.21      1.90     -4.06     11.58     13.50      1.00\n",
      "  alpha[36,1]      0.42      3.17      0.28     -4.42      6.19     12.17      1.03\n",
      "  alpha[36,2]     -3.17      4.02     -2.92    -10.06      2.95     11.87      1.00\n",
      "  alpha[36,3]    -25.94     29.56    -20.37    -66.79     18.78    234.73      1.00\n",
      "  alpha[37,0]      0.56      5.57      0.74     -8.12     10.50     59.11      1.03\n",
      "  alpha[37,1]      0.69      3.28      0.51     -4.54      6.11     10.58      1.02\n",
      "  alpha[37,2]     -2.63      4.16     -2.43     -9.22      3.50     19.29      1.01\n",
      "  alpha[37,3]    -19.07     31.35    -13.94    -72.01     23.73    275.46      1.01\n",
      "  alpha[38,0]      3.21      5.14      2.11     -4.25     11.63     12.83      1.00\n",
      "  alpha[38,1]      0.66      3.33      0.28     -4.45      6.65     10.41      1.02\n",
      "  alpha[38,2]     -3.60      4.16     -3.22     -9.95      3.09     10.75      1.00\n",
      "  alpha[38,3]    -28.98     25.61    -23.97    -68.79      4.46    126.32      1.03\n",
      "  alpha[39,0]      0.55      5.74      0.48     -7.41     11.26     44.09      1.02\n",
      "  alpha[39,1]      0.79      3.34      0.55     -4.54      6.11     10.70      1.02\n",
      "  alpha[39,2]     -2.82      4.17     -2.55     -9.40      3.52     14.76      1.01\n",
      "  alpha[39,3]    -20.48     29.00    -15.87    -67.70     22.16    601.94      1.01\n",
      "  alpha[40,0]      0.76      5.37      0.62     -7.26     10.43     30.91      1.03\n",
      "  alpha[40,1]      0.64      3.23      0.39     -4.44      5.83     10.46      1.02\n",
      "  alpha[40,2]     -2.57      4.07     -2.49     -8.59      4.37     17.96      1.00\n",
      "  alpha[40,3]    -21.83     29.62    -16.41    -67.54     23.11    418.68      1.01\n",
      "  alpha[41,0]      0.00      5.49      0.09     -8.50     10.24     32.56      1.04\n",
      "  alpha[41,1]      0.80      3.20      0.58     -4.47      6.04      9.41      1.04\n",
      "  alpha[41,2]     -2.83      3.91     -2.60     -8.85      3.26     15.13      1.00\n",
      "  alpha[41,3]    -16.25     35.46    -10.97    -74.28     37.21    418.38      1.00\n",
      "  alpha[42,0]     -0.92      5.33     -0.36     -9.26      7.65     26.60      1.06\n",
      "  alpha[42,1]      0.78      3.39      0.40     -4.27      6.87     10.11      1.02\n",
      "  alpha[42,2]     -2.14      3.75     -2.06     -8.18      3.69     15.32      1.02\n",
      "  alpha[42,3]    -19.12     30.73    -15.20    -62.63     32.31    405.69      1.00\n",
      "  alpha[43,0]      0.44      5.48      0.47     -7.86      9.89     41.27      1.02\n",
      "  alpha[43,1]      0.70      3.22      0.48     -4.26      6.63     11.31      1.02\n",
      "  alpha[43,2]     -2.77      4.12     -2.57     -9.87      2.76     15.60      1.01\n",
      "  alpha[43,3]    -20.28     30.90    -15.88    -63.84     27.85    313.45      1.01\n",
      "  alpha[44,0]      0.31      5.55      0.35     -8.45      9.62     33.24      1.04\n",
      "  alpha[44,1]      0.75      3.24      0.38     -3.67      7.17     11.62      1.02\n",
      "  alpha[44,2]     -2.87      4.14     -2.51     -9.56      3.95     13.45      1.01\n",
      "  alpha[44,3]     38.59     25.94     33.21      2.09     72.42     88.00      1.01\n",
      "  alpha[45,0]      0.23      5.39      0.24     -9.56      8.67     43.88      1.02\n",
      "  alpha[45,1]      0.80      3.28      0.58     -4.36      6.56     11.39      1.01\n",
      "  alpha[45,2]     -2.68      4.04     -2.53     -9.48      3.48     14.92      1.01\n",
      "  alpha[45,3]     27.98     27.12     21.69    -10.31     68.13     67.70      1.01\n",
      "  alpha[46,0]      0.61      5.57      0.40     -7.96     10.26     46.01      1.02\n",
      "  alpha[46,1]      0.72      3.24      0.44     -3.81      6.35     11.41      1.02\n",
      "  alpha[46,2]     -2.65      3.97     -2.51     -9.31      3.27     17.18      1.00\n",
      "  alpha[46,3]    -22.10     30.81    -16.98    -67.84     27.52    203.66      1.01\n",
      "  alpha[47,0]     -2.85      5.09     -1.67    -10.50      4.96     17.28      1.09\n",
      "  alpha[47,1]      0.48      3.04      0.23     -4.34      5.41     12.20      1.02\n",
      "  alpha[47,2]     -0.63      3.89     -0.91     -7.85      4.79     16.01      1.04\n",
      "  alpha[47,3]    -30.34     26.91    -24.33    -71.74      5.52    128.63      1.01\n",
      "  alpha[48,0]      0.55      5.19      0.48     -6.95      9.69     35.44      1.04\n",
      "  alpha[48,1]      0.66      3.21      0.38     -5.25      5.60     10.13      1.03\n",
      "  alpha[48,2]     -2.73      4.15     -2.51    -10.11      2.98     16.68      1.01\n",
      "  alpha[48,3]     44.77     26.72     40.14      4.23     78.56     46.90      1.01\n",
      "  alpha[49,0]      0.44      5.45      0.35     -6.91     10.60     33.90      1.04\n",
      "  alpha[49,1]      0.70      3.27      0.45     -4.07      6.22     11.27      1.02\n",
      "  alpha[49,2]     -2.74      3.98     -2.42     -8.71      4.20     18.57      1.00\n",
      "  alpha[49,3]     28.51     27.38     22.39     -9.70     72.66     69.46      1.01\n",
      "  alpha[50,0]     -0.02      5.53      0.20    -10.88      7.97     32.69      1.04\n",
      "  alpha[50,1]      0.67      3.19      0.39     -4.85      5.81     11.28      1.03\n",
      "  alpha[50,2]     -2.67      4.09     -2.58     -9.91      3.33     13.84      1.00\n",
      "  alpha[50,3]     24.44     30.02     17.49    -19.84     67.10    158.01      1.02\n",
      "  alpha[51,0]      0.12      5.85      0.51     -9.11      9.80     29.81      1.04\n",
      "  alpha[51,1]      0.78      3.20      0.57     -4.41      6.20      9.86      1.02\n",
      "  alpha[51,2]     -2.83      3.94     -2.49     -9.58      2.91     13.20      1.01\n",
      "  alpha[51,3]     27.98     27.62     21.94     -8.42     67.71     67.50      1.02\n",
      "  alpha[52,0]      0.14      5.30      0.27     -6.80     10.15     41.22      1.02\n",
      "  alpha[52,1]      0.62      3.28      0.27     -4.56      6.00     11.72      1.02\n",
      "  alpha[52,2]     -2.68      3.93     -2.51     -8.91      4.12     15.89      1.01\n",
      "  alpha[52,3]     32.60     27.66     24.97     -3.60     77.55    111.19      1.00\n",
      "  alpha[53,0]      0.38      5.68      0.49     -8.44     10.28     34.32      1.04\n",
      "  alpha[53,1]      0.76      3.46      0.57     -4.23      6.99     10.87      1.02\n",
      "  alpha[53,2]     -2.57      3.98     -2.48     -9.40      2.97     18.93      1.01\n",
      "  alpha[53,3]    -19.84     30.68    -15.59    -62.73     31.62    292.12      1.01\n",
      "  alpha[54,0]     -0.49      5.90      0.04     -9.98     10.17     28.89      1.04\n",
      "  alpha[54,1]      0.71      3.19      0.50     -4.84      5.68     11.01      1.03\n",
      "  alpha[54,2]     -2.79      4.07     -2.64     -9.47      3.34     17.35      1.00\n",
      "  alpha[54,3]     49.00     26.16     44.76      7.72     88.02     37.56      1.02\n",
      "  alpha[55,0]      0.23      5.69      0.39     -9.67      9.26     31.51      1.03\n",
      "  alpha[55,1]      0.73      3.36      0.34     -4.11      6.59     10.50      1.02\n",
      "  alpha[55,2]     -2.64      3.89     -2.36     -8.41      3.86     13.40      1.01\n",
      "  alpha[55,3]    -18.80     32.69    -12.38    -68.87     28.92    318.35      1.00\n",
      "  alpha[56,0]      0.12      5.62      0.35     -8.38     10.19     35.38      1.03\n",
      "  alpha[56,1]      0.79      3.32      0.40     -4.17      6.88     10.11      1.03\n",
      "  alpha[56,2]     -2.80      3.96     -2.64     -9.04      4.00     15.31      1.01\n",
      "  alpha[56,3]    -22.46     28.93    -16.87    -71.51     17.20    342.72      1.01\n",
      "  alpha[57,0]      1.25      5.33      0.71     -7.26      9.97     48.59      1.00\n",
      "  alpha[57,1]      0.55      3.40      0.28     -3.81      7.05     14.31      1.02\n",
      "  alpha[57,2]     -2.71      4.05     -2.47     -8.68      3.93     17.39      1.00\n",
      "  alpha[57,3]    -26.88     29.41    -20.37    -71.48     16.91    170.37      1.01\n",
      "  alpha[58,0]      1.67      4.99      0.99     -5.79     10.52     19.67      1.02\n",
      "  alpha[58,1]      0.55      3.08      0.32     -4.83      5.22     10.96      1.02\n",
      "  alpha[58,2]     -2.72      3.99     -2.57     -9.43      3.00     15.35      1.00\n",
      "  alpha[58,3]    -30.89     25.74    -25.65    -70.77      4.58    196.96      1.00\n",
      "  alpha[59,0]      0.41      5.65      0.36     -9.33      9.46     30.51      1.03\n",
      "  alpha[59,1]      0.70      3.17      0.51     -4.66      5.92     10.27      1.02\n",
      "  alpha[59,2]     -2.69      4.32     -2.43     -9.86      3.71     14.91      1.01\n",
      "  alpha[59,3]     34.64     26.67     28.09     -0.85     73.24     79.54      1.02\n",
      "  alpha[60,0]      1.57      5.30      1.05     -6.09     11.56     25.75      1.01\n",
      "  alpha[60,1]      0.72      3.31      0.44     -4.35      6.45     12.44      1.02\n",
      "  alpha[60,2]     -3.04      4.08     -2.78    -10.09      2.63     15.37      1.01\n",
      "  alpha[60,3]    -27.04     27.48    -22.03    -69.30     12.33    409.28      1.00\n",
      "  alpha[61,0]      0.46      5.34      0.54     -8.75      8.66     36.03      1.02\n",
      "  alpha[61,1]      0.74      3.36      0.37     -4.51      6.35     10.77      1.03\n",
      "  alpha[61,2]     -2.80      4.01     -2.44     -9.29      3.30     15.79      1.01\n",
      "  alpha[61,3]    -20.93     28.13    -16.00    -67.60     20.54    191.80      1.00\n",
      "  alpha[62,0]      0.38      5.98      0.42     -9.91     10.65     36.39      1.03\n",
      "  alpha[62,1]      0.73      3.24      0.43     -4.41      6.15     10.00      1.02\n",
      "  alpha[62,2]     -2.76      4.00     -2.49     -9.95      3.23     13.67      1.00\n",
      "  alpha[62,3]     41.32     26.63     34.64      4.88     80.07     55.45      1.02\n",
      "  alpha[63,0]      0.33      5.66      0.54     -7.73      9.05     27.93      1.04\n",
      "  alpha[63,1]      0.77      3.23      0.61     -4.34      6.57      9.81      1.02\n",
      "  alpha[63,2]     -2.80      3.92     -2.51     -9.19      3.08     14.25      1.01\n",
      "  alpha[63,3]    -27.69     29.01    -23.04    -72.98     16.14    255.38      1.01\n",
      "  alpha[64,0]      0.27      5.26      0.29     -8.59      8.11     46.42      1.03\n",
      "  alpha[64,1]      0.59      3.09      0.37     -4.04      5.98     11.59      1.02\n",
      "  alpha[64,2]     -2.78      4.05     -2.37     -9.15      3.72     13.08      1.00\n",
      "  alpha[64,3]     44.18     25.41     37.57     11.28     80.76     48.00      1.02\n",
      "  alpha[65,0]      0.11      5.46      0.20     -8.79      9.76     36.83      1.03\n",
      "  alpha[65,1]      0.75      3.22      0.48     -3.73      6.70      9.63      1.03\n",
      "  alpha[65,2]     -2.78      4.12     -2.49     -9.33      3.65     17.06      1.01\n",
      "  alpha[65,3]     21.67     26.81     16.07    -14.68     63.28    412.13      1.00\n",
      "  alpha[66,0]     -0.08      5.53      0.16     -8.30      9.26     29.86      1.05\n",
      "  alpha[66,1]      0.81      3.19      0.41     -3.74      6.66      9.57      1.03\n",
      "  alpha[66,2]     -2.51      4.01     -2.27     -9.31      3.59     13.79      1.01\n",
      "  alpha[66,3]    -23.57     31.15    -17.77    -67.93     24.19    279.41      1.00\n",
      "  alpha[67,0]     -0.08      5.46      0.02    -10.07      7.89     26.43      1.05\n",
      "  alpha[67,1]      0.72      3.19      0.51     -3.99      6.39     10.74      1.02\n",
      "  alpha[67,2]     -2.76      4.22     -2.58    -10.11      3.71     15.76      1.00\n",
      "  alpha[67,3]     35.85     25.73     30.49      2.81     78.53     68.12      1.01\n",
      "  alpha[68,0]      0.10      5.63      0.30     -8.60      9.61     31.18      1.04\n",
      "  alpha[68,1]      0.67      3.25      0.39     -4.19      6.63     11.75      1.02\n",
      "  alpha[68,2]     -2.86      3.95     -2.58     -8.97      3.65     14.32      1.00\n",
      "  alpha[68,3]     35.28     29.23     28.75     -0.88     80.60     82.04      1.01\n",
      "  alpha[69,0]      1.83      5.22      1.22     -5.44     11.05     22.16      1.01\n",
      "  alpha[69,1]      0.54      3.10      0.25     -3.97      5.97     11.61      1.02\n",
      "  alpha[69,2]     -2.85      4.22     -2.81     -9.53      3.27     19.27      1.00\n",
      "  alpha[69,3]    -22.25     30.80    -16.31    -65.27     23.80    271.12      1.00\n",
      "  alpha[70,0]      0.17      5.19      0.24     -8.08      9.12     23.62      1.04\n",
      "  alpha[70,1]      0.78      3.28      0.53     -5.56      5.57     10.21      1.02\n",
      "  alpha[70,2]     -2.67      3.81     -2.45     -9.80      2.68     15.77      1.00\n",
      "  alpha[70,3]     23.10     31.04     16.20    -21.13     69.86    134.33      1.00\n",
      "  alpha[71,0]     -4.37      6.34     -2.67    -14.13      4.99     16.44      1.06\n",
      "  alpha[71,1]      1.63      3.69      1.17     -3.95      7.84      7.71      1.04\n",
      "  alpha[71,2]     -2.74      3.89     -2.41     -9.14      2.95     16.27      1.01\n",
      "  alpha[71,3]    -37.82     26.44    -32.35    -76.23     -2.17     73.67      1.01\n",
      "  alpha[72,0]      0.09      6.20      0.58     -8.27     10.91     26.88      1.04\n",
      "  alpha[72,1]      0.70      3.12      0.56     -5.31      5.30     10.85      1.02\n",
      "  alpha[72,2]     -2.66      4.07     -2.43     -9.43      3.33     15.07      1.01\n",
      "  alpha[72,3]    -16.20     32.60    -12.59    -65.05     36.40    454.38      1.00\n",
      "  alpha[73,0]      0.11      5.44      0.28     -8.17     10.05     40.17      1.02\n",
      "  alpha[73,1]      0.79      3.23      0.64     -4.38      6.46     10.44      1.02\n",
      "  alpha[73,2]     -2.77      3.84     -2.57     -9.84      2.31     13.75      1.01\n",
      "  alpha[73,3]     30.47     26.53     24.17     -6.14     68.88     68.95      1.01\n",
      "  alpha[74,0]      0.34      5.50      0.50     -8.39     10.02     40.84      1.02\n",
      "  alpha[74,1]      0.58      3.20      0.41     -4.39      6.09     14.32      1.02\n",
      "  alpha[74,2]     -2.71      3.97     -2.73     -9.01      3.91     14.94      1.01\n",
      "  alpha[74,3]     45.91     23.47     40.35     10.07     79.34     50.18      1.01\n",
      "  alpha[75,0]      0.11      5.02      0.31     -8.03      8.49     33.31      1.04\n",
      "  alpha[75,1]      0.88      3.36      0.57     -3.89      7.28      9.95      1.03\n",
      "  alpha[75,2]     -2.89      4.03     -2.70     -8.62      4.12     15.03      1.01\n",
      "  alpha[75,3]    -26.43     29.48    -19.65    -71.41     13.62    297.45      1.01\n",
      "  alpha[76,0]      0.21      5.39      0.42     -8.15      9.84     28.61      1.04\n",
      "  alpha[76,1]      0.62      3.14      0.39     -4.83      5.68     11.27      1.02\n",
      "  alpha[76,2]     -2.70      4.05     -2.66     -9.64      2.76     16.99      1.00\n",
      "  alpha[76,3]     41.44     25.72     35.99      1.85     77.75     43.51      1.03\n",
      "  alpha[77,0]      1.03      5.34      0.77     -6.56     10.67     25.90      1.02\n",
      "  alpha[77,1]      0.73      3.18      0.43     -4.25      5.95      9.54      1.03\n",
      "  alpha[77,2]     -2.85      4.13     -2.49     -9.09      3.99     14.16      1.01\n",
      "  alpha[77,3]    -29.08     27.78    -23.01    -71.64      7.64    248.94      1.00\n",
      "  alpha[78,0]     -0.20      5.89      0.04     -9.62      9.51     31.62      1.05\n",
      "  alpha[78,1]      0.74      3.32      0.35     -3.85      7.06     10.31      1.03\n",
      "  alpha[78,2]     -2.63      4.03     -2.50     -9.18      3.72     16.90      1.01\n",
      "  alpha[78,3]     47.94     25.12     43.47     12.21     87.78     46.46      1.03\n",
      "  alpha[79,0]      0.57      5.53      0.57     -7.95      9.92     28.53      1.03\n",
      "  alpha[79,1]      0.72      3.42      0.42     -3.98      7.13     13.01      1.01\n",
      "  alpha[79,2]     -2.81      3.88     -2.55     -8.87      3.73     13.23      1.00\n",
      "  alpha[79,3]    -25.32     29.59    -19.86    -67.07     22.33    274.81      1.01\n",
      "  alpha[80,0]      0.38      5.74      0.55     -8.41     10.41     54.52      1.02\n",
      "  alpha[80,1]      0.70      3.16      0.43     -3.38      7.22     10.59      1.02\n",
      "  alpha[80,2]     -2.81      4.12     -2.66     -9.19      3.47     15.05      1.00\n",
      "  alpha[80,3]     25.14     26.36     20.47    -14.90     61.41    128.84      1.00\n",
      "  alpha[81,0]     -0.02      5.84      0.27     -9.19      9.76     35.13      1.03\n",
      "  alpha[81,1]      0.64      3.30      0.49     -3.94      6.45     12.18      1.02\n",
      "  alpha[81,2]     -2.73      3.88     -2.59     -9.82      2.82     13.48      1.01\n",
      "  alpha[81,3]     34.69     24.39     29.16     -1.39     70.75    142.72      1.01\n",
      "  alpha[82,0]      0.89      5.29      0.72     -6.28     11.12     44.18      1.02\n",
      "  alpha[82,1]      0.75      3.38      0.38     -4.61      6.49     10.10      1.03\n",
      "  alpha[82,2]     -2.69      3.91     -2.43     -8.79      4.11     13.36      1.00\n",
      "  alpha[82,3]    -15.86     30.80    -11.72    -70.01     27.21    356.49      1.00\n",
      "  alpha[83,0]      0.54      5.61      0.42     -8.13     10.37     41.66      1.04\n",
      "  alpha[83,1]      0.71      3.30      0.39     -4.21      6.50     10.42      1.03\n",
      "  alpha[83,2]     -2.53      3.98     -2.38     -9.79      3.06     13.57      1.01\n",
      "  alpha[83,3]    -18.62     29.72    -13.88    -63.26     26.39    699.92      1.00\n",
      "  alpha[84,0]      0.14      6.05      0.49     -8.63     10.87     33.42      1.03\n",
      "  alpha[84,1]      0.78      3.16      0.53     -4.15      6.21     10.01      1.02\n",
      "  alpha[84,2]     -2.73      3.88     -2.50     -9.33      3.01     14.82      1.00\n",
      "  alpha[84,3]    -22.75     31.29    -17.38    -67.09     26.83    357.48      1.00\n",
      "  alpha[85,0]      5.11      5.75      3.85     -2.09     14.89      9.80      1.00\n",
      "  alpha[85,1]      0.02      3.02     -0.07     -5.17      4.74     16.50      1.01\n",
      "  alpha[85,2]     -2.82      3.98     -2.54     -9.77      2.99     12.50      1.00\n",
      "  alpha[85,3]    -41.98     26.31    -36.36    -82.17     -5.33    145.54      1.02\n",
      "  alpha[86,0]     -0.06      5.22      0.27     -8.63      8.59     29.45      1.05\n",
      "  alpha[86,1]      0.77      3.26      0.55     -4.36      6.50     10.54      1.02\n",
      "  alpha[86,2]     -2.82      4.17     -2.45     -9.29      3.92     16.23      1.00\n",
      "  alpha[86,3]    -20.75     29.97    -15.61    -65.94     22.28    320.90      1.00\n",
      "  alpha[87,0]      3.70      5.18      2.45     -3.10     12.16     10.24      1.00\n",
      "  alpha[87,1]      0.47      3.10      0.24     -4.75      5.22     12.07      1.02\n",
      "  alpha[87,2]     -3.33      4.06     -2.98    -10.19      2.68     13.00      1.00\n",
      "  alpha[87,3]    -42.76     25.77    -37.12    -81.46     -3.94     80.84      1.02\n",
      "  alpha[88,0]      1.17      5.27      0.81     -8.26      8.58     37.61      1.02\n",
      "  alpha[88,1]      0.63      3.32      0.33     -4.04      6.54     12.95      1.02\n",
      "  alpha[88,2]     -2.91      4.20     -2.51     -9.25      3.95     13.64      1.01\n",
      "  alpha[88,3]    -20.73     29.88    -15.30    -62.92     24.46    461.74      1.01\n",
      "  alpha[89,0]     -2.56      5.77     -1.39    -11.75      5.49     20.84      1.06\n",
      "  alpha[89,1]      0.66      3.20      0.44     -3.82      6.93     10.76      1.02\n",
      "  alpha[89,2]     -1.17      3.99     -1.39     -8.30      4.47     21.79      1.02\n",
      "  alpha[89,3]    -28.55     28.70    -22.13    -70.82     14.55    248.45      1.00\n",
      "  alpha[90,0]      0.17      5.66      0.32     -6.86     11.53     53.57      1.02\n",
      "  alpha[90,1]      0.69      3.30      0.38     -4.40      6.55     11.27      1.02\n",
      "  alpha[90,2]     -2.70      3.97     -2.36     -9.42      2.99     15.53      1.01\n",
      "  alpha[90,3]     17.89     28.08     14.20    -26.39     60.98    327.94      1.00\n",
      "  alpha[91,0]      0.40      5.41      0.37     -8.59      9.95     33.83      1.02\n",
      "  alpha[91,1]      0.69      3.24      0.38     -4.25      6.59     12.06      1.03\n",
      "  alpha[91,2]     -2.69      3.85     -2.55     -8.51      3.85     15.13      1.01\n",
      "  alpha[91,3]    -13.80     31.92     -8.18    -64.80     37.38    303.53      1.00\n",
      "  alpha[92,0]      0.37      5.51      0.38     -8.57      9.76     29.49      1.04\n",
      "  alpha[92,1]      0.80      3.43      0.44     -4.16      6.63     10.68      1.03\n",
      "  alpha[92,2]     -2.81      3.91     -2.65     -8.70      3.46     12.78      1.01\n",
      "  alpha[92,3]    -14.30     33.97     -9.40    -68.33     37.13    811.28      1.00\n",
      "  alpha[93,0]      0.46      5.52      0.46     -7.38     11.04     43.88      1.02\n",
      "  alpha[93,1]      0.74      3.17      0.48     -4.75      5.56     10.19      1.02\n",
      "  alpha[93,2]     -2.65      3.93     -2.40     -8.84      3.80     14.32      1.00\n",
      "  alpha[93,3]    -14.55     32.78    -11.35    -63.76     41.11    753.48      1.00\n",
      "  alpha[94,0]      1.61      5.31      0.86     -6.15     11.50     30.30      1.01\n",
      "  alpha[94,1]      0.75      3.33      0.39     -4.45      6.21     11.49      1.02\n",
      "  alpha[94,2]     -3.09      3.96     -2.90    -10.14      2.54     14.39      1.00\n",
      "  alpha[94,3]    -27.12     25.12    -22.72    -67.85      7.83    278.24      1.00\n",
      "  alpha[95,0]      0.07      5.36      0.16    -10.64      7.46     40.17      1.04\n",
      "  alpha[95,1]      0.65      3.25      0.39     -4.31      6.10     10.69      1.02\n",
      "  alpha[95,2]     -2.78      4.17     -2.72     -9.71      3.42     14.46      1.01\n",
      "  alpha[95,3]     30.61     27.57     23.59     -8.17     71.16     55.65      1.02\n",
      "  alpha[96,0]     -0.08      5.34      0.13     -8.82      8.62     34.08      1.03\n",
      "  alpha[96,1]      0.89      3.34      0.56     -4.54      6.54      9.77      1.02\n",
      "  alpha[96,2]     -2.67      4.10     -2.53     -9.41      3.83     12.21      1.01\n",
      "  alpha[96,3]    -28.77     28.58    -23.20    -68.55     12.24    131.79      1.02\n",
      "  alpha[97,0]      3.06      5.22      1.98     -4.07     11.95     13.55      1.01\n",
      "  alpha[97,1]      0.37      3.17      0.11     -4.42      6.14     13.15      1.02\n",
      "  alpha[97,2]     -3.06      4.16     -2.80    -10.30      2.97     14.12      1.00\n",
      "  alpha[97,3]    -37.13     27.18    -32.17    -73.44      5.40    113.46      1.01\n",
      "  alpha[98,0]      0.47      5.42      0.41     -7.85      9.95     41.80      1.02\n",
      "  alpha[98,1]      0.67      3.19      0.35     -3.70      7.04     11.05      1.02\n",
      "  alpha[98,2]     -2.70      4.11     -2.55     -8.97      4.19     14.50      1.00\n",
      "  alpha[98,3]    -21.61     30.24    -15.16    -67.12     24.09    229.48      1.00\n",
      "  alpha[99,0]      0.40      5.40      0.42     -7.83      9.93     41.23      1.03\n",
      "  alpha[99,1]      0.71      3.30      0.25     -4.01      6.67     11.18      1.03\n",
      "  alpha[99,2]     -3.05      4.29     -2.73    -10.16      3.63     12.91      1.00\n",
      "  alpha[99,3]     41.99     26.94     36.80      5.74     81.81     45.29      1.02\n",
      " alpha[100,0]      0.02      5.50      0.34     -7.72      9.46     35.42      1.03\n",
      " alpha[100,1]      0.80      3.19      0.51     -3.88      6.74      9.52      1.02\n",
      " alpha[100,2]     -2.80      3.88     -2.64    -10.52      2.38     11.76      1.01\n",
      " alpha[100,3]    -24.90     25.58    -20.28    -66.78     13.01    516.09      1.00\n",
      " alpha[101,0]     -0.05      5.63      0.15     -9.04      9.47     32.95      1.04\n",
      " alpha[101,1]      0.75      3.27      0.25     -4.13      6.55     10.95      1.02\n",
      " alpha[101,2]     -2.78      4.09     -2.60     -9.70      2.97     14.78      1.00\n",
      " alpha[101,3]     30.97     26.54     24.05     -2.02     71.83     77.54      1.01\n",
      " alpha[102,0]      1.60      4.94      1.09     -5.96     10.45     28.06      1.01\n",
      " alpha[102,1]      0.70      3.19      0.40     -3.44      7.07     11.01      1.02\n",
      " alpha[102,2]     -3.00      4.04     -2.83     -9.88      2.88     12.68      1.00\n",
      " alpha[102,3]    -31.07     29.71    -24.45    -76.22      8.93    207.50      1.01\n",
      " alpha[103,0]      3.71      5.13      2.40     -2.73     12.96     10.34      1.00\n",
      " alpha[103,1]      0.53      3.20      0.31     -4.26      6.07     12.18      1.01\n",
      " alpha[103,2]     -3.30      4.05     -2.95     -9.07      3.29     11.91      1.00\n",
      " alpha[103,3]    -43.46     24.08    -39.73    -77.35     -5.17     92.81      1.01\n",
      " alpha[104,0]      1.57      4.96      1.03     -5.35     11.05     23.18      1.02\n",
      " alpha[104,1]      0.72      3.36      0.41     -4.80      6.18     10.91      1.02\n",
      " alpha[104,2]     -3.16      4.12     -2.87    -10.26      2.99     13.03      1.00\n",
      " alpha[104,3]    -24.53     28.67    -17.75    -67.00     16.94    380.61      1.00\n",
      " alpha[105,0]      0.54      5.71      0.59     -7.72     10.67     49.88      1.01\n",
      " alpha[105,1]      0.71      3.21      0.44     -4.25      6.06     11.10      1.02\n",
      " alpha[105,2]     -2.67      4.31     -2.26     -9.85      3.45     17.82      1.00\n",
      " alpha[105,3]    -20.09     29.15    -14.99    -64.08     24.17    320.15      1.00\n",
      " alpha[106,0]     -0.26      5.14      0.24     -8.45      8.86     36.95      1.02\n",
      " alpha[106,1]      0.94      3.28      0.54     -3.62      6.73      8.91      1.03\n",
      " alpha[106,2]     -2.79      3.73     -2.39     -9.22      3.01     15.25      1.01\n",
      " alpha[106,3]    -34.80     27.66    -28.77    -73.71      3.16    212.54      1.00\n",
      " alpha[107,0]     -2.98      5.30     -1.71    -12.28      4.00     17.25      1.08\n",
      " alpha[107,1]      0.38      3.04      0.20     -3.71      6.46     14.07      1.02\n",
      " alpha[107,2]     -0.67      3.85     -0.82     -6.50      6.12     16.23      1.04\n",
      " alpha[107,3]    -31.22     28.54    -24.81    -72.83      7.42     91.39      1.02\n",
      " alpha[108,0]      0.19      5.55      0.49     -9.54      9.37     42.66      1.02\n",
      " alpha[108,1]      0.73      3.27      0.48     -4.11      6.61     10.24      1.03\n",
      " alpha[108,2]     -2.74      4.02     -2.47     -9.26      3.21     14.02      1.01\n",
      " alpha[108,3]     38.85     25.27     32.88      4.86     79.15     57.93      1.02\n",
      " alpha[109,0]      0.26      5.71      0.25     -8.97      9.70     35.86      1.03\n",
      " alpha[109,1]      0.75      3.16      0.48     -3.99      6.38      9.50      1.02\n",
      " alpha[109,2]     -2.92      3.96     -2.57     -9.22      3.45     11.77      1.00\n",
      " alpha[109,3]     39.47     28.07     31.98      1.81     82.06     52.85      1.02\n",
      " alpha[110,0]      3.10      5.23      2.02     -4.30     12.26     12.20      1.01\n",
      " alpha[110,1]      0.71      3.17      0.43     -4.58      6.12     10.00      1.03\n",
      " alpha[110,2]     -3.56      3.95     -3.43     -9.93      2.69     11.61      1.00\n",
      " alpha[110,3]    -30.17     26.63    -24.16    -67.56      9.44    196.49      1.00\n",
      " alpha[111,0]      0.16      5.47      0.26     -8.57      9.76     31.82      1.04\n",
      " alpha[111,1]      0.62      3.18      0.38     -4.36      5.80     11.33      1.02\n",
      " alpha[111,2]     -2.71      3.88     -2.51     -9.57      2.77     14.18      1.00\n",
      " alpha[111,3]     52.18     28.06     47.30     15.08     90.73     40.66      1.01\n",
      " alpha[112,0]      0.94      5.25      0.64     -8.16      8.84     40.16      1.01\n",
      " alpha[112,1]      0.68      3.15      0.48     -4.74      5.60     10.72      1.02\n",
      " alpha[112,2]     -2.94      4.09     -2.52     -9.90      3.15     13.92      1.01\n",
      " alpha[112,3]    -17.76     30.79    -13.14    -64.39     32.14    490.43      1.00\n",
      " alpha[113,0]     -0.11      5.48      0.32     -9.25      9.36     32.10      1.04\n",
      " alpha[113,1]      0.75      3.20      0.45     -3.81      6.76     11.05      1.02\n",
      " alpha[113,2]     -2.75      4.13     -2.44     -9.83      2.81     15.17      1.00\n",
      " alpha[113,3]     34.70     25.45     28.80     -0.38     71.75     64.41      1.01\n",
      " alpha[114,0]      0.88      5.31      0.61     -7.47     10.51     24.86      1.03\n",
      " alpha[114,1]      0.69      3.26      0.47     -4.04      6.88     10.58      1.02\n",
      " alpha[114,2]     -2.67      4.20     -2.47     -9.17      3.57     16.75      1.00\n",
      " alpha[114,3]    -24.66     28.39    -20.07    -70.30     12.64    234.93      1.02\n",
      " alpha[115,0]      0.78      5.24      0.57     -7.77      9.98     33.33      1.01\n",
      " alpha[115,1]      0.69      3.27      0.44     -4.02      6.92     10.89      1.03\n",
      " alpha[115,2]     -2.80      4.07     -2.50     -9.81      3.23     14.75      1.00\n",
      " alpha[115,3]    -27.59     29.01    -20.59    -73.28     15.36    149.11      1.02\n",
      " alpha[116,0]      0.04      5.82      0.21     -8.28     10.43     30.09      1.04\n",
      " alpha[116,1]      0.70      3.24      0.40     -4.03      6.89     10.90      1.03\n",
      " alpha[116,2]     -2.79      4.09     -2.53     -9.67      3.14     15.38      1.00\n",
      " alpha[116,3]     30.75     24.62     25.91     -5.61     68.09    105.87      1.01\n",
      " alpha[117,0]      0.27      5.29      0.34     -7.94      9.15     45.54      1.02\n",
      " alpha[117,1]      0.71      3.28      0.42     -5.35      5.77     11.16      1.02\n",
      " alpha[117,2]     -2.63      4.06     -2.39     -9.80      3.16     15.01      1.01\n",
      " alpha[117,3]     21.81     31.33     17.13    -21.70     65.14    199.80      1.00\n",
      " alpha[118,0]      0.61      5.49      0.58     -9.11      9.62     49.62      1.02\n",
      " alpha[118,1]      0.69      3.17      0.43     -3.92      6.46     10.32      1.02\n",
      " alpha[118,2]     -2.66      3.90     -2.59     -9.80      2.66     15.62      1.01\n",
      " alpha[118,3]    -18.04     27.21    -14.66    -61.34     25.19    474.53      1.01\n",
      " alpha[119,0]     -0.51      5.83      0.15     -8.68      9.25     28.90      1.04\n",
      " alpha[119,1]      0.99      3.40      0.70     -4.19      6.57      9.35      1.03\n",
      " alpha[119,2]     -2.65      4.11     -2.45     -9.16      3.85     16.54      1.01\n",
      " alpha[119,3]    -34.61     28.30    -28.45    -75.50      6.72    144.43      1.02\n",
      " alpha[120,0]      0.53      5.44      0.42     -8.92      8.99     65.42      1.01\n",
      " alpha[120,1]      0.75      3.20      0.56     -4.11      6.43     10.15      1.02\n",
      " alpha[120,2]     -2.82      3.93     -2.64     -8.84      3.11     14.96      1.00\n",
      " alpha[120,3]    -18.93     30.47    -13.57    -68.92     24.79    317.03      1.01\n",
      " alpha[121,0]     -0.18      5.25      0.19    -10.22      7.42     32.60      1.03\n",
      " alpha[121,1]      0.74      3.28      0.44     -4.61      6.12     10.42      1.02\n",
      " alpha[121,2]     -2.34      3.82     -2.32     -8.43      3.60     15.20      1.00\n",
      " alpha[121,3]    -22.03     30.01    -15.21    -68.63     21.46    546.48      1.00\n",
      " alpha[122,0]      0.34      5.36      0.55     -9.04      8.32     36.37      1.03\n",
      " alpha[122,1]      0.70      3.21      0.43     -4.46      6.33     10.21      1.02\n",
      " alpha[122,2]     -2.85      3.91     -2.71     -8.93      3.46     12.09      1.01\n",
      " alpha[122,3]     33.13     26.03     27.31     -6.10     69.04     84.63      1.01\n",
      " alpha[123,0]      0.07      5.37      0.29     -8.03      9.16     32.97      1.03\n",
      " alpha[123,1]      0.79      3.15      0.49     -4.51      5.62      9.30      1.03\n",
      " alpha[123,2]     -2.80      4.22     -2.46     -9.39      3.53     19.05      1.01\n",
      " alpha[123,3]    -32.45     24.59    -28.90    -66.18      6.32    168.35      1.00\n",
      " alpha[124,0]      0.64      5.40      0.30     -7.28     10.06     31.36      1.03\n",
      " alpha[124,1]      0.71      3.18      0.47     -4.45      6.01     11.51      1.03\n",
      " alpha[124,2]     -2.71      3.96     -2.48     -9.64      2.78     14.47      1.00\n",
      " alpha[124,3]    -21.46     33.43    -14.75    -74.85     26.45    157.08      1.01\n",
      " alpha[125,0]      3.27      5.36      1.87     -4.52     11.26     12.50      1.01\n",
      " alpha[125,1]      0.47      3.15      0.16     -4.06      6.44     11.62      1.02\n",
      " alpha[125,2]     -2.89      3.93     -2.64     -9.27      3.12     12.63      1.01\n",
      " alpha[125,3]    -36.84     26.14    -32.98    -77.61      3.32    106.49      1.01\n",
      " alpha[126,0]      1.10      5.13      0.74     -6.66      9.96     34.40      1.02\n",
      " alpha[126,1]      0.79      3.17      0.56     -4.30      6.16      9.96      1.02\n",
      " alpha[126,2]     -2.69      4.12     -2.54     -9.30      3.81     15.11      1.00\n",
      " alpha[126,3]    -28.82     26.63    -24.12    -70.72      9.34    285.34      1.01\n",
      " alpha[127,0]      0.30      5.41      0.47     -8.67      9.30     34.48      1.03\n",
      " alpha[127,1]      0.64      3.27      0.35     -4.64      6.34     11.98      1.02\n",
      " alpha[127,2]     -2.71      3.98     -2.61     -9.59      3.36     14.89      1.00\n",
      " alpha[127,3]     33.31     24.78     27.07      1.30     70.81    127.24      1.01\n",
      " alpha[128,0]      1.99      4.96      1.41     -6.43      9.38     21.64      1.01\n",
      " alpha[128,1]      0.59      3.10      0.41     -3.86      6.15     11.06      1.02\n",
      " alpha[128,2]     -3.10      3.92     -2.80    -10.49      2.44     12.74      1.00\n",
      " alpha[128,3]    -17.83     33.35    -11.95    -69.46     34.14    260.26      1.01\n",
      " alpha[129,0]     -0.00      5.55      0.32    -10.21      8.43     47.70      1.02\n",
      " alpha[129,1]      0.75      3.43      0.46     -4.03      7.19     11.83      1.03\n",
      " alpha[129,2]     -2.62      4.14     -2.44     -9.11      3.96     17.00      1.01\n",
      " alpha[129,3]     25.21     26.82     19.21    -15.37     65.02    204.59      1.00\n",
      " alpha[130,0]      0.21      5.66      0.25     -9.46      9.65     37.23      1.03\n",
      " alpha[130,1]      0.66      3.20      0.37     -3.45      7.24     11.70      1.02\n",
      " alpha[130,2]     -2.81      4.30     -2.55     -9.49      3.89     14.17      1.00\n",
      " alpha[130,3]     33.23     24.94     27.73     -3.45     67.20     44.21      1.01\n",
      " alpha[131,0]     -0.23      5.35      0.15     -8.65      9.24     33.38      1.04\n",
      " alpha[131,1]      0.83      3.24      0.46     -3.34      7.03      9.43      1.03\n",
      " alpha[131,2]     -2.79      4.17     -2.57     -9.20      4.06     15.27      1.01\n",
      " alpha[131,3]    -28.71     28.47    -22.68    -71.67     10.80    221.01      1.01\n",
      " alpha[132,0]      0.41      5.66      0.51     -7.94     10.70     27.45      1.03\n",
      " alpha[132,1]      0.63      3.27      0.25     -4.50      6.60     12.15      1.02\n",
      " alpha[132,2]     -2.82      4.12     -2.39    -10.12      3.16     16.47      1.00\n",
      " alpha[132,3]     18.71     29.09     13.74    -27.96     64.36    665.12      1.00\n",
      " alpha[133,0]     -0.00      5.23      0.17     -9.30      8.54     37.58      1.03\n",
      " alpha[133,1]      0.68      3.18      0.43     -4.30      6.16     11.03      1.02\n",
      " alpha[133,2]     -2.78      4.06     -2.53     -9.34      2.83     14.80      1.00\n",
      " alpha[133,3]     36.31     26.60     31.45     -1.56     74.30     81.61      1.01\n",
      " alpha[134,0]      0.25      5.79      0.24     -9.24      9.02     48.07      1.03\n",
      " alpha[134,1]      0.67      3.12      0.45     -4.25      6.44     10.77      1.02\n",
      " alpha[134,2]     -2.68      4.18     -2.39     -9.03      3.59     17.50      1.01\n",
      " alpha[134,3]     29.94     22.52     26.01     -1.38     64.64    110.79      1.01\n",
      " alpha[135,0]      1.50      5.22      0.94     -7.13     10.19     24.15      1.01\n",
      " alpha[135,1]      0.61      3.24      0.35     -4.38      6.22     11.36      1.02\n",
      " alpha[135,2]     -3.03      3.95     -2.76     -9.63      3.09     13.72      1.00\n",
      " alpha[135,3]    -22.98     27.20    -18.40    -62.53     17.77    352.76      1.00\n",
      " alpha[136,0]      0.42      5.48      0.35     -8.79      9.61     42.50      1.02\n",
      " alpha[136,1]      0.73      3.25      0.44     -3.81      6.71     10.55      1.03\n",
      " alpha[136,2]     -2.78      4.03     -2.68     -9.64      3.10     15.79      1.00\n",
      " alpha[136,3]    -16.97     31.93    -11.51    -66.74     29.72    562.24      1.00\n",
      " alpha[137,0]      0.30      5.58      0.44     -7.32     10.36     30.94      1.03\n",
      " alpha[137,1]      0.65      3.05      0.41     -3.86      6.23     10.04      1.03\n",
      " alpha[137,2]     -2.81      3.99     -2.48     -9.24      3.23     15.00      1.00\n",
      " alpha[137,3]     30.70     27.46     23.89     -6.30     69.13     73.03      1.00\n",
      " alpha[138,0]      1.07      5.27      0.73     -5.80     11.26     62.08      1.00\n",
      " alpha[138,1]      0.74      3.15      0.55     -3.53      6.69     10.49      1.03\n",
      " alpha[138,2]     -2.90      4.08     -2.64     -9.62      3.02     15.04      1.00\n",
      " alpha[138,3]    -16.57     30.05    -13.20    -63.79     31.09    674.06      1.00\n",
      " alpha[139,0]     -0.20      4.92      0.26     -8.55      7.74     35.00      1.03\n",
      " alpha[139,1]      0.78      3.18      0.46     -3.83      6.46      9.00      1.03\n",
      " alpha[139,2]     -2.80      3.95     -2.64     -9.88      2.42     13.90      1.00\n",
      " alpha[139,3]    -31.25     26.26    -25.47    -70.70      2.33    189.30      1.00\n",
      " alpha[140,0]      0.47      5.22      0.62     -8.27      9.25     41.52      1.02\n",
      " alpha[140,1]      0.67      3.23      0.40     -4.46      6.24     10.17      1.03\n",
      " alpha[140,2]     -2.75      4.11     -2.43    -10.12      3.31     17.85      1.01\n",
      " alpha[140,3]     55.07     25.79     51.05     15.46     88.89     30.81      1.01\n",
      " alpha[141,0]     -1.27      5.21     -0.50     -9.95      6.15     26.59      1.04\n",
      " alpha[141,1]      0.99      3.37      0.62     -3.80      7.05      8.87      1.03\n",
      " alpha[141,2]     -2.78      4.13     -2.63     -9.75      3.39     14.45      1.00\n",
      " alpha[141,3]    -31.03     28.07    -24.32    -75.38      6.87     95.38      1.02\n",
      " alpha[142,0]     -0.26      5.68      0.32    -10.93      8.61     30.50      1.04\n",
      " alpha[142,1]      0.89      3.26      0.63     -4.52      6.48      9.51      1.03\n",
      " alpha[142,2]     -2.77      4.13     -2.46     -9.50      3.40     15.51      1.00\n",
      " alpha[142,3]    -21.14     28.89    -16.50    -64.06     27.32    264.01      1.00\n",
      " alpha[143,0]     -0.77      5.88     -0.12    -11.56      8.03     25.74      1.05\n",
      " alpha[143,1]      0.75      3.15      0.43     -4.61      5.82     10.30      1.02\n",
      " alpha[143,2]     -2.66      4.19     -2.40     -9.03      3.54     16.59      1.01\n",
      " alpha[143,3]     53.90     26.35     49.51     10.16     91.40     27.64      1.01\n",
      " alpha[144,0]      0.44      5.21      0.58     -8.12      9.03     35.82      1.03\n",
      " alpha[144,1]      0.72      3.28      0.27     -4.61      6.60     10.03      1.03\n",
      " alpha[144,2]     -2.68      3.84     -2.52     -8.55      3.26     13.40      1.01\n",
      " alpha[144,3]    -17.60     31.51    -12.13    -67.39     27.50    431.62      1.00\n",
      " alpha[145,0]      0.22      5.21      0.32     -8.81      8.49     40.20      1.03\n",
      " alpha[145,1]      0.73      3.26      0.41     -4.33      6.36     10.78      1.02\n",
      " alpha[145,2]     -2.82      4.18     -2.51     -9.25      3.83     13.24      1.01\n",
      " alpha[145,3]    -20.06     27.78    -15.09    -64.49     21.67    570.19      1.01\n",
      " alpha[146,0]     -0.49      5.02     -0.08     -9.69      6.81     30.28      1.04\n",
      " alpha[146,1]      0.23      3.10      0.01     -4.22      6.13     15.25      1.02\n",
      " alpha[146,2]     -1.27      3.75     -1.37     -7.41      4.76     18.13      1.03\n",
      " alpha[146,3]    -40.17     24.59    -35.29    -77.74     -6.09    160.68      1.00\n",
      " alpha[147,0]      0.46      5.37      0.34     -8.09      9.59     43.90      1.02\n",
      " alpha[147,1]      0.73      3.07      0.58     -4.18      6.14      9.72      1.02\n",
      " alpha[147,2]     -2.76      4.03     -2.57     -9.06      4.11     14.60      1.01\n",
      " alpha[147,3]     22.95     28.76     17.79    -21.22     63.63    171.38      1.01\n",
      " alpha[148,0]      0.09      5.66      0.26     -8.47      9.20     37.46      1.03\n",
      " alpha[148,1]      0.71      3.31      0.46     -3.87      7.05     10.33      1.03\n",
      " alpha[148,2]     -2.69      3.91     -2.60     -9.96      2.33     14.32      1.01\n",
      " alpha[148,3]     29.90     28.97     23.70    -11.27     72.87     90.93      1.01\n",
      " alpha[149,0]     -0.02      5.47      0.42     -9.18      8.76     33.70      1.05\n",
      " alpha[149,1]      0.66      3.37      0.40     -4.15      6.65     12.90      1.02\n",
      " alpha[149,2]     -2.85      3.96     -2.70     -9.90      2.40     15.47      1.00\n",
      " alpha[149,3]     33.25     26.85     28.25     -6.17     67.67     76.64      1.01\n",
      " alpha[150,0]      0.77      5.58      0.56     -8.78      9.29     34.79      1.03\n",
      " alpha[150,1]      0.69      3.34      0.45     -4.78      6.19     11.72      1.02\n",
      " alpha[150,2]     -2.88      3.93     -2.64    -10.38      2.68     14.51      1.01\n",
      " alpha[150,3]    -21.60     31.46    -16.35    -72.16     24.61    210.25      1.02\n",
      " alpha[151,0]      0.50      5.98      0.24     -7.13     12.05     31.94      1.04\n",
      " alpha[151,1]      0.85      3.28      0.52     -4.36      6.15      9.77      1.03\n",
      " alpha[151,2]     -2.92      4.03     -2.52    -10.64      2.64     13.70      1.01\n",
      " alpha[151,3]    -26.03     29.81    -21.49    -70.80     17.91    243.68      1.00\n",
      " alpha[152,0]      0.37      5.59      0.38     -7.79     10.29     53.94      1.02\n",
      " alpha[152,1]      0.71      3.34      0.42     -4.85      6.22     11.18      1.02\n",
      " alpha[152,2]     -2.68      3.90     -2.52     -9.01      3.61     12.29      1.01\n",
      " alpha[152,3]    -14.86     33.87    -10.51    -69.18     34.69    355.37      1.01\n",
      " alpha[153,0]      0.28      5.48      0.33     -7.71     10.56     33.23      1.03\n",
      " alpha[153,1]      0.51      3.14      0.28     -4.25      6.05     13.69      1.02\n",
      " alpha[153,2]     -2.80      4.14     -2.72     -9.10      3.50     14.12      1.00\n",
      " alpha[153,3]     56.73     26.18     53.14     12.60     93.26     22.20      1.03\n",
      " alpha[154,0]      0.10      5.49      0.31    -10.34      8.15     31.95      1.04\n",
      " alpha[154,1]      0.56      3.10      0.37     -4.09      6.31     11.62      1.02\n",
      " alpha[154,2]     -2.66      4.06     -2.36     -9.37      3.38     14.36      1.01\n",
      " alpha[154,3]     41.80     25.37     37.20      2.74     78.31     46.05      1.02\n",
      " alpha[155,0]      0.19      5.66      0.42     -8.89      8.91     28.80      1.03\n",
      " alpha[155,1]      0.53      3.22      0.20     -4.53      5.88     11.17      1.02\n",
      " alpha[155,2]     -2.69      3.97     -2.47     -9.47      3.29     14.50      1.01\n",
      " alpha[155,3]     45.94     25.12     40.00      7.87     81.33     48.30      1.01\n",
      " alpha[156,0]      0.29      5.51      0.20     -8.22     10.32     44.63      1.03\n",
      " alpha[156,1]      0.78      3.25      0.48     -4.64      6.53      9.15      1.03\n",
      " alpha[156,2]     -2.90      3.84     -2.61     -8.99      3.58     13.59      1.01\n",
      " alpha[156,3]    -23.16     32.29    -16.85    -71.17     27.53    471.00      1.01\n",
      " alpha[157,0]     -0.34      5.72     -0.02    -10.73      9.26     30.99      1.05\n",
      " alpha[157,1]      0.73      3.32      0.43     -4.73      6.32     11.12      1.02\n",
      " alpha[157,2]     -2.78      3.93     -2.66     -9.22      3.08     15.05      1.01\n",
      " alpha[157,3]     44.72     25.09     38.32      7.67     82.85     47.03      1.01\n",
      " alpha[158,0]     -0.02      5.21      0.24     -7.88      9.87     24.31      1.05\n",
      " alpha[158,1]      0.80      3.41      0.36     -3.78      7.19     10.26      1.02\n",
      " alpha[158,2]     -2.59      4.03     -2.38     -8.95      3.35     12.47      1.01\n",
      " alpha[158,3]     23.96     25.33     19.61    -10.16     64.58    307.54      1.01\n",
      " alpha[159,0]      0.79      5.79      0.66     -8.34     10.89     42.69      1.02\n",
      " alpha[159,1]      0.79      3.28      0.47     -4.05      6.83     10.53      1.02\n",
      " alpha[159,2]     -2.69      4.24     -2.54     -8.98      3.75     20.19      1.00\n",
      " alpha[159,3]    -19.96     30.70    -14.82    -69.74     23.94    360.52      1.00\n",
      " alpha[160,0]      0.53      5.51      0.43     -7.39     10.30     45.38      1.02\n",
      " alpha[160,1]      0.72      3.14      0.51     -4.26      6.19     10.05      1.02\n",
      " alpha[160,2]     -2.44      4.11     -2.31     -8.72      4.28     15.76      1.01\n",
      " alpha[160,3]    -22.42     31.51    -17.31    -71.49     21.56    228.02      1.01\n",
      " alpha[161,0]     -1.04      5.91     -0.39     -8.64      9.02     28.51      1.04\n",
      " alpha[161,1]      1.63      3.71      1.16     -3.29      8.74      6.93      1.05\n",
      " alpha[161,2]     -3.89      3.95     -3.54    -10.18      2.11     10.45      1.00\n",
      " alpha[161,3]    -29.13     26.74    -23.65    -65.48      8.00    363.49      1.00\n",
      " alpha[162,0]      0.18      5.64      0.38    -10.86      8.49     29.76      1.04\n",
      " alpha[162,1]      0.63      3.14      0.43     -4.08      5.96     11.10      1.02\n",
      " alpha[162,2]     -2.64      3.95     -2.50     -9.21      3.15     13.34      1.00\n",
      " alpha[162,3]    -19.20     31.57    -14.33    -64.69     29.84    493.22      1.00\n",
      " alpha[163,0]      0.48      5.13      0.54     -6.79     10.06     45.93      1.02\n",
      " alpha[163,1]      0.83      3.34      0.64     -4.03      6.81     10.84      1.02\n",
      " alpha[163,2]     -2.71      4.24     -2.38     -9.17      3.98     19.23      1.00\n",
      " alpha[163,3]     16.20     28.58     11.77    -23.12     63.93    226.72      1.00\n",
      " alpha[164,0]      0.21      5.41      0.30     -7.71     10.03     42.70      1.03\n",
      " alpha[164,1]      0.60      3.15      0.40     -4.41      5.83     10.99      1.02\n",
      " alpha[164,2]     -2.75      4.16     -2.38     -8.97      3.44     17.34      1.00\n",
      " alpha[164,3]     33.58     25.54     27.43     -4.05     69.47     70.18      1.01\n",
      " alpha[165,0]     -0.34      5.33     -0.00     -8.12      8.51     35.46      1.04\n",
      " alpha[165,1]      0.76      3.30      0.55     -4.37      6.68     11.56      1.02\n",
      " alpha[165,2]     -2.64      3.98     -2.47     -9.32      3.58     15.83      1.01\n",
      " alpha[165,3]     46.42     24.78     41.00     11.18     83.68     50.05      1.02\n",
      " alpha[166,0]      1.26      5.52      0.85     -7.86     10.64     52.10      1.01\n",
      " alpha[166,1]      0.73      3.29      0.52     -4.29      6.33     10.73      1.03\n",
      " alpha[166,2]     -2.87      4.24     -2.77    -10.90      2.81     15.42      1.00\n",
      " alpha[166,3]    -28.86     29.09    -23.89    -74.22     12.85    276.41      1.01\n",
      " alpha[167,0]      0.25      5.34      0.34     -6.80     10.30     44.96      1.02\n",
      " alpha[167,1]      0.72      3.25      0.50     -3.96      6.74     11.20      1.02\n",
      " alpha[167,2]     -2.74      3.93     -2.55     -9.71      2.89     16.88      1.00\n",
      " alpha[167,3]    -11.73     31.94     -6.94    -60.35     38.16    782.87      1.00\n",
      " alpha[168,0]      0.04      5.62      0.39     -8.41     10.50     35.93      1.03\n",
      " alpha[168,1]      0.58      3.20      0.35     -4.04      6.43     11.98      1.02\n",
      " alpha[168,2]     -2.81      3.98     -2.47     -9.27      3.15     13.01      1.00\n",
      " alpha[168,3]     32.37     27.59     26.59     -3.38     71.72     70.91      1.01\n",
      " alpha[169,0]     -3.30      6.07     -1.77    -13.30      5.09     22.34      1.05\n",
      " alpha[169,1]      1.29      3.64      0.86     -3.85      7.37      8.10      1.04\n",
      " alpha[169,2]     -2.87      3.83     -2.66     -9.41      2.74     12.98      1.00\n",
      " alpha[169,3]    -24.68     31.30    -19.18    -69.30     24.40    145.36      1.01\n",
      " alpha[170,0]     -0.16      5.31      0.19     -7.10      9.39     36.96      1.03\n",
      " alpha[170,1]      0.88      3.30      0.60     -3.73      7.42      9.23      1.03\n",
      " alpha[170,2]     -2.76      4.16     -2.44     -9.84      3.20     12.73      1.01\n",
      " alpha[170,3]    -37.22     30.33    -32.28    -81.70     10.06     63.33      1.02\n",
      " alpha[171,0]      0.20      5.65      0.22     -9.76      9.79     26.27      1.04\n",
      " alpha[171,1]      0.64      3.27      0.27     -3.89      6.61     11.38      1.02\n",
      " alpha[171,2]     -2.79      3.93     -2.56     -9.91      2.85     15.45      1.01\n",
      " alpha[171,3]     32.27     28.20     25.54     -4.85     74.75    120.62      1.01\n",
      " alpha[172,0]      0.33      5.46      0.36     -9.81      8.70     47.42      1.02\n",
      " alpha[172,1]      0.80      3.26      0.53     -4.00      6.73     10.72      1.02\n",
      " alpha[172,2]     -2.76      3.99     -2.48     -9.95      2.80     14.72      1.00\n",
      " alpha[172,3]    -17.70     28.36    -14.46    -58.34     21.86    489.56      1.00\n",
      " alpha[173,0]     -2.02      5.24     -1.07    -10.87      6.25     24.70      1.06\n",
      " alpha[173,1]      1.10      3.31      0.79     -3.40      7.61      9.05      1.03\n",
      " alpha[173,2]     -2.67      3.88     -2.50     -9.77      2.80     13.95      1.01\n",
      " alpha[173,3]    -18.85     31.70    -13.44    -62.84     30.47    233.93      1.01\n",
      " alpha[174,0]     -0.17      5.24      0.11     -8.82      8.13     33.33      1.03\n",
      " alpha[174,1]      0.72      3.27      0.50     -4.17      6.85     10.72      1.02\n",
      " alpha[174,2]     -2.88      4.07     -2.73     -9.12      3.84     17.16      1.00\n",
      " alpha[174,3]     30.23     26.10     24.49     -3.57     69.24     86.31      1.01\n",
      " alpha[175,0]      0.03      5.47      0.33     -7.11     10.66     35.34      1.03\n",
      " alpha[175,1]      0.75      3.31      0.43     -4.58      6.18     10.91      1.02\n",
      " alpha[175,2]     -2.73      4.13     -2.51     -9.70      3.48     14.79      1.00\n",
      " alpha[175,3]     23.75     27.15     17.47    -14.58     61.29    295.71      1.00\n",
      " alpha[176,0]      0.06      5.49      0.20     -9.58      8.81     29.71      1.04\n",
      " alpha[176,1]      0.76      3.34      0.47     -3.62      7.58     10.72      1.03\n",
      " alpha[176,2]     -2.91      4.09     -2.55     -9.90      3.35     13.74      1.00\n",
      " alpha[176,3]     25.65     28.79     19.82    -17.04     68.20    113.67      1.00\n",
      " alpha[177,0]      0.28      5.35      0.30     -8.65      8.75     28.47      1.04\n",
      " alpha[177,1]      0.64      3.34      0.35     -4.95      6.19     11.38      1.02\n",
      " alpha[177,2]     -2.74      4.12     -2.56     -9.19      3.67     15.25      1.01\n",
      " alpha[177,3]     30.84     28.48     25.02    -13.21     68.13     65.59      1.03\n",
      " alpha[178,0]     -0.39      5.63     -0.03     -9.00     10.49     22.67      1.06\n",
      " alpha[178,1]      0.68      3.16      0.49     -4.02      6.64      9.81      1.02\n",
      " alpha[178,2]     -2.81      4.09     -2.57     -9.48      3.53     14.83      1.01\n",
      " alpha[178,3]     45.03     25.22     39.42      9.63     83.24     45.36      1.00\n",
      " alpha[179,0]      0.49      5.59      0.36     -9.46      8.61     53.26      1.03\n",
      " alpha[179,1]      0.70      3.35      0.28     -4.84      6.23     10.07      1.03\n",
      " alpha[179,2]     -2.79      4.28     -2.53    -10.05      3.73     14.40      1.00\n",
      " alpha[179,3]    -21.02     30.58    -16.08    -67.99     25.12    208.55      1.00\n",
      " alpha[180,0]      0.22      5.23      0.26     -7.00     10.24     38.07      1.02\n",
      " alpha[180,1]      0.63      3.20      0.26     -4.25      6.46     11.58      1.01\n",
      " alpha[180,2]     -2.81      3.93     -2.73     -9.25      3.31     15.14      1.00\n",
      " alpha[180,3]     24.27     29.97     18.90    -23.86     66.96    354.10      1.00\n",
      " alpha[181,0]      0.19      5.50      0.30     -8.02     10.47     36.13      1.03\n",
      " alpha[181,1]      0.69      3.14      0.51     -3.62      7.12     10.35      1.02\n",
      " alpha[181,2]     -2.85      4.08     -2.41     -9.46      3.46     18.49      1.01\n",
      " alpha[181,3]     27.39     27.99     22.66    -16.50     67.47    130.79      1.02\n",
      " alpha[182,0]      0.39      5.66      0.54     -9.14      9.77     47.08      1.02\n",
      " alpha[182,1]      0.72      3.30      0.36     -3.89      7.05     11.69      1.02\n",
      " alpha[182,2]     -2.63      4.03     -2.51     -9.28      3.52     14.65      1.01\n",
      " alpha[182,3]    -10.24     30.31     -7.32    -58.16     37.35    402.66      1.00\n",
      " alpha[183,0]      0.30      5.12      0.41     -7.44      9.22     34.66      1.03\n",
      " alpha[183,1]      0.73      3.18      0.47     -4.21      6.29     10.81      1.02\n",
      " alpha[183,2]     -2.69      4.03     -2.35     -8.97      3.91     15.19      1.00\n",
      " alpha[183,3]    -18.93     32.32    -13.99    -66.74     33.03    409.49      1.00\n",
      " alpha[184,0]      0.28      5.77      0.40     -8.30     10.18     34.56      1.03\n",
      " alpha[184,1]      0.66      3.22      0.42     -4.53      6.21     11.65      1.02\n",
      " alpha[184,2]     -2.78      4.06     -2.51     -9.15      3.59     14.04      1.01\n",
      " alpha[184,3]     30.70     26.23     24.23     -4.86     70.54     55.48      1.01\n",
      " alpha[185,0]      1.06      5.65      0.77     -9.91      9.56     35.95      1.01\n",
      " alpha[185,1]      0.71      3.15      0.47     -3.98      6.49     10.66      1.02\n",
      " alpha[185,2]     -2.87      4.10     -2.57     -9.56      3.55     14.03      1.00\n",
      " alpha[185,3]    -28.29     26.67    -23.42    -70.79      7.70    194.65      1.01\n",
      " alpha[186,0]      0.87      5.47      0.80     -7.87      9.74     56.02      1.01\n",
      " alpha[186,1]      0.70      3.31      0.39     -4.36      6.70     10.43      1.03\n",
      " alpha[186,2]     -2.73      4.18     -2.54     -9.54      3.23     14.04      1.01\n",
      " alpha[186,3]    -23.37     29.13    -17.88    -67.28     22.07    227.60      1.01\n",
      " alpha[187,0]     -0.29      5.75      0.03    -11.45      8.20     28.67      1.05\n",
      " alpha[187,1]      0.76      3.19      0.54     -4.33      6.41     10.50      1.03\n",
      " alpha[187,2]     -2.60      4.05     -2.46    -10.23      3.00     16.92      1.01\n",
      " alpha[187,3]     32.74     28.58     24.91     -7.60     74.34     84.67      1.01\n",
      " alpha[188,0]      0.16      5.44      0.33     -8.37      9.41     49.73      1.02\n",
      " alpha[188,1]      0.82      3.29      0.49     -4.62      6.41     10.35      1.02\n",
      " alpha[188,2]     -2.80      4.20     -2.61     -9.09      3.83     16.35      1.01\n",
      " alpha[188,3]     16.78     29.86     11.95    -30.23     58.84    245.96      1.00\n",
      " alpha[189,0]      0.21      5.59      0.30     -8.71      9.41     42.08      1.02\n",
      " alpha[189,1]      0.79      3.25      0.57     -3.42      7.17      9.87      1.02\n",
      " alpha[189,2]     -2.79      3.92     -2.61     -9.19      3.39     16.57      1.00\n",
      " alpha[189,3]    -35.44     28.44    -29.84    -73.70      9.27     96.33      1.01\n",
      " alpha[190,0]     -4.62      6.38     -2.73    -14.81      3.91     14.55      1.09\n",
      " alpha[190,1]      0.64      3.18      0.47     -3.73      6.62     11.01      1.02\n",
      " alpha[190,2]     -0.63      3.94     -0.83     -6.88      6.21     19.13      1.05\n",
      " alpha[190,3]    -26.65     26.85    -20.75    -70.67     10.10    472.15      1.00\n",
      " alpha[191,0]      3.23      4.91      2.26     -3.56     11.95     11.30      1.00\n",
      " alpha[191,1]      0.27      3.00      0.09     -5.25      4.94     13.77      1.02\n",
      " alpha[191,2]     -2.86      4.01     -2.53     -9.47      2.95     15.40      1.00\n",
      " alpha[191,3]    -12.69     31.36     -9.22    -62.29     35.41    709.34      1.00\n",
      " alpha[192,0]      0.89      5.58      0.67     -7.27     11.15     54.13      1.01\n",
      " alpha[192,1]      0.70      3.22      0.44     -4.12      6.29      9.99      1.03\n",
      " alpha[192,2]     -2.72      4.00     -2.59     -9.57      2.96     14.57      1.01\n",
      " alpha[192,3]    -24.41     29.74    -18.07    -68.38     21.25    165.45      1.01\n",
      " alpha[193,0]      0.49      5.23      0.45     -8.27      9.30     25.25      1.04\n",
      " alpha[193,1]      0.74      3.25      0.40     -3.49      7.02     11.00      1.02\n",
      " alpha[193,2]     -3.05      4.05     -2.71     -8.99      3.67     13.16      1.00\n",
      " alpha[193,3]     48.52     26.14     43.30      9.56     82.46     43.30      1.02\n",
      " alpha[194,0]      0.10      5.21      0.25     -9.88      7.73     35.79      1.03\n",
      " alpha[194,1]      0.81      3.39      0.49     -4.08      6.59      9.99      1.02\n",
      " alpha[194,2]     -2.89      4.20     -2.66     -8.97      4.14     16.38      1.00\n",
      " alpha[194,3]    -27.08     29.76    -21.64    -69.08     18.62    213.01      1.00\n",
      " alpha[195,0]      0.64      5.48      0.62     -8.07      9.47     41.45      1.02\n",
      " alpha[195,1]      0.64      3.31      0.43     -4.48      6.49     10.79      1.03\n",
      " alpha[195,2]     -2.75      4.11     -2.34     -9.07      4.18     13.32      1.00\n",
      " alpha[195,3]    -21.24     30.56    -16.11    -70.49     22.18    257.15      1.01\n",
      " alpha[196,0]      0.79      5.07      0.68     -7.16      9.42     43.65      1.02\n",
      " alpha[196,1]      0.72      3.20      0.44     -4.69      5.75     10.80      1.02\n",
      " alpha[196,2]     -2.72      4.04     -2.49     -9.06      3.86     15.70      1.00\n",
      " alpha[196,3]    -22.92     32.16    -17.87    -70.78     23.31    352.92      1.00\n",
      " alpha[197,0]     -0.92      5.31     -0.45     -9.67      7.86     27.83      1.05\n",
      " alpha[197,1]      0.67      3.21      0.33     -4.21      6.64     10.69      1.02\n",
      " alpha[197,2]     -2.12      3.82     -2.03     -8.92      3.37     17.57      1.02\n",
      " alpha[197,3]    -17.83     30.78    -13.30    -64.03     32.31    741.39      1.01\n",
      " alpha[198,0]      0.41      5.94      0.53     -8.27     10.33     28.53      1.04\n",
      " alpha[198,1]      0.70      3.27      0.36     -4.18      6.50     10.24      1.02\n",
      " alpha[198,2]     -2.84      4.05     -2.74     -9.01      3.69     15.16      1.00\n",
      " alpha[198,3]     41.46     26.16     37.34      2.23     81.79    132.84      1.00\n",
      " alpha[199,0]      0.21      5.33      0.30     -7.97      8.74     30.17      1.04\n",
      " alpha[199,1]      0.72      3.31      0.43     -3.66      7.24     10.43      1.03\n",
      " alpha[199,2]     -2.87      4.24     -2.48     -9.33      3.91     14.43      1.01\n",
      " alpha[199,3]     -7.00     36.97     -5.96    -62.00     58.34    622.51      1.00\n",
      " alpha[200,0]      3.67      5.07      2.53     -3.41     11.73      9.12      1.01\n",
      " alpha[200,1]      0.45      3.06      0.27     -4.85      5.21     12.16      1.02\n",
      " alpha[200,2]     -3.19      3.97     -2.75     -9.64      2.70     11.10      1.00\n",
      " alpha[200,3]    -44.07     25.51    -39.40    -82.28     -7.47     64.54      1.02\n",
      " alpha[201,0]      0.43      5.57      0.40     -7.78     10.63     33.07      1.04\n",
      " alpha[201,1]      0.77      3.27      0.46     -4.09      6.72     10.30      1.03\n",
      " alpha[201,2]     -2.78      3.91     -2.59     -9.09      3.08     13.50      1.01\n",
      " alpha[201,3]    -13.96     33.61     -9.13    -65.10     37.01    646.87      1.01\n",
      " alpha[202,0]      0.14      5.54      0.38     -8.80      9.06     41.42      1.03\n",
      " alpha[202,1]      0.67      3.25      0.43     -5.00      5.61     11.24      1.02\n",
      " alpha[202,2]     -2.82      4.10     -2.63     -9.37      3.42     18.40      1.01\n",
      " alpha[202,3]     24.21     26.96     18.99    -13.37     64.48    119.88      1.00\n",
      " alpha[203,0]     -0.16      5.84      0.18     -9.83     10.32     27.18      1.04\n",
      " alpha[203,1]      0.69      3.27      0.41     -4.39      6.26     10.36      1.02\n",
      " alpha[203,2]     -2.64      4.11     -2.35     -9.46      3.74     16.19      1.00\n",
      " alpha[203,3]     21.85     27.18     17.03    -13.45     66.54    190.33      1.00\n",
      " alpha[204,0]      0.13      5.47      0.40     -8.61     10.29     36.73      1.03\n",
      " alpha[204,1]      0.62      3.34      0.22     -4.56      6.40     11.94      1.02\n",
      " alpha[204,2]     -2.61      3.85     -2.45     -8.96      3.25     13.93      1.01\n",
      " alpha[204,3]    -27.21     29.36    -21.29    -70.09     15.55    140.10      1.01\n",
      " alpha[205,0]      0.37      5.36      0.46     -8.09      9.85     47.81      1.02\n",
      " alpha[205,1]      0.74      3.28      0.37     -4.39      6.54     10.68      1.01\n",
      " alpha[205,2]     -2.76      4.16     -2.45    -10.24      3.01     15.74      1.00\n",
      " alpha[205,3]     20.60     28.83     15.77    -20.78     61.71    312.65      1.01\n",
      " alpha[206,0]      0.06      5.75      0.29     -9.25     10.06     42.39      1.03\n",
      " alpha[206,1]      0.72      3.25      0.53     -3.60      6.92     11.54      1.02\n",
      " alpha[206,2]     -2.75      4.25     -2.64     -9.75      3.65     16.07      1.00\n",
      " alpha[206,3]     27.26     27.71     21.52    -11.13     67.56     68.62      1.01\n",
      " alpha[207,0]      0.01      6.19      0.43     -8.43     10.56     21.68      1.05\n",
      " alpha[207,1]      0.67      3.18      0.37     -4.31      6.27     11.02      1.02\n",
      " alpha[207,2]     -2.70      4.08     -2.55     -9.34      3.55     13.57      1.01\n",
      " alpha[207,3]     20.27     27.73     15.48    -21.51     62.41    188.94      1.01\n",
      " alpha[208,0]     -0.11      5.18      0.05    -10.29      7.39     45.81      1.02\n",
      " alpha[208,1]      0.84      3.41      0.51     -3.78      6.91     10.25      1.02\n",
      " alpha[208,2]     -2.75      4.03     -2.49    -10.29      2.69     16.22      1.01\n",
      " alpha[208,3]    -13.92     31.53     -9.63    -61.73     35.60    590.21      1.00\n",
      " alpha[209,0]     -0.48      5.76      0.04    -11.74      7.86     32.02      1.04\n",
      " alpha[209,1]      0.65      3.16      0.39     -3.93      6.33     10.88      1.03\n",
      " alpha[209,2]     -2.64      4.08     -2.38     -9.29      3.53     14.85      1.01\n",
      " alpha[209,3]     48.75     25.87     43.64      8.15     87.56     49.99      1.01\n",
      " alpha[210,0]      0.04      5.51      0.24     -8.14      9.85     37.72      1.04\n",
      " alpha[210,1]      0.71      3.45      0.31     -4.34      6.98     12.57      1.02\n",
      " alpha[210,2]     -2.69      4.05     -2.46     -9.07      4.04     15.77      1.01\n",
      " alpha[210,3]     31.75     26.68     25.52     -4.32     70.16    118.31      1.01\n",
      " alpha[211,0]      0.31      5.78      0.42     -7.35     11.52     62.62      1.01\n",
      " alpha[211,1]      0.71      3.15      0.39     -4.10      6.29     10.07      1.02\n",
      " alpha[211,2]     -2.65      3.97     -2.36     -9.28      3.56     16.37      1.00\n",
      " alpha[211,3]    -18.23     30.67    -12.56    -67.36     25.69    621.14      1.00\n",
      " alpha[212,0]      0.41      5.59      0.43     -7.66     11.50     43.20      1.03\n",
      " alpha[212,1]      0.73      3.21      0.39     -3.96      6.49     10.10      1.03\n",
      " alpha[212,2]     -2.70      4.17     -2.40     -9.40      3.78     16.21      1.01\n",
      " alpha[212,3]    -20.82     31.86    -15.33    -64.79     30.51    245.42      1.01\n",
      " alpha[213,0]      0.26      5.38      0.43     -8.33      8.92     33.82      1.03\n",
      " alpha[213,1]      0.75      3.16      0.41     -3.60      6.81      9.65      1.02\n",
      " alpha[213,2]     -2.79      4.12     -2.61     -9.70      3.74     14.58      1.01\n",
      " alpha[213,3]    -18.41     29.92    -13.52    -65.27     25.89    397.26      1.01\n",
      " alpha[214,0]     -0.30      5.11      0.27     -8.51      8.00     28.50      1.05\n",
      " alpha[214,1]      0.81      3.34      0.45     -4.93      6.02      9.42      1.03\n",
      " alpha[214,2]     -2.79      4.18     -2.48     -8.99      4.05     18.10      1.00\n",
      " alpha[214,3]    -31.56     26.17    -25.32    -74.49      1.81     98.01      1.02\n",
      " alpha[215,0]     -0.42      5.11      0.01     -8.31      7.76     44.02      1.03\n",
      " alpha[215,1]      0.87      3.31      0.44     -3.75      7.04      8.82      1.03\n",
      " alpha[215,2]     -2.77      4.16     -2.57     -9.65      3.66     14.75      1.00\n",
      " alpha[215,3]    -22.17     26.77    -17.91    -58.11     20.68    312.02      1.01\n",
      " alpha[216,0]     -0.00      5.47      0.32     -8.35      9.08     45.48      1.02\n",
      " alpha[216,1]      0.77      3.37      0.43     -4.30      6.56      9.79      1.03\n",
      " alpha[216,2]     -2.92      3.94     -2.52     -9.99      2.71     14.72      1.00\n",
      " alpha[216,3]    -24.11     28.32    -17.83    -66.02     15.67    386.23      1.00\n",
      " alpha[217,0]     -1.39      5.07     -0.58     -9.01      7.62     25.04      1.04\n",
      " alpha[217,1]      1.51      3.60      1.10     -3.76      7.77      7.41      1.03\n",
      " alpha[217,2]     -3.48      3.88     -3.22    -10.53      1.97     10.83      1.00\n",
      " alpha[217,3]    -25.33     28.47    -19.35    -67.42     16.28    179.42      1.00\n",
      " alpha[218,0]      0.25      5.58      0.39     -7.51     11.01     38.84      1.03\n",
      " alpha[218,1]      0.74      3.24      0.40     -4.28      6.35      9.32      1.03\n",
      " alpha[218,2]     -2.67      4.11     -2.53    -10.70      2.65     13.11      1.00\n",
      " alpha[218,3]    -22.66     27.65    -16.98    -65.44     19.30    292.78      1.00\n",
      " alpha[219,0]      0.12      5.52      0.26     -7.33     10.50     26.17      1.05\n",
      " alpha[219,1]      0.72      3.15      0.48     -4.14      6.09     10.37      1.03\n",
      " alpha[219,2]     -2.63      3.97     -2.45     -9.82      3.33     17.26      1.00\n",
      " alpha[219,3]     29.42     27.40     23.83     -7.43     71.45     76.60      1.01\n",
      " alpha[220,0]      0.18      5.82      0.47     -9.61     10.57     35.25      1.03\n",
      " alpha[220,1]      0.58      3.14      0.37     -4.81      5.69     11.23      1.03\n",
      " alpha[220,2]     -2.58      3.99     -2.41     -9.63      3.16     14.45      1.01\n",
      " alpha[220,3]     35.46     25.07     29.61      0.94     71.27     92.63      1.00\n",
      " alpha[221,0]      0.31      5.49      0.44     -8.22      9.44     46.67      1.01\n",
      " alpha[221,1]      0.72      3.15      0.63     -4.10      6.36     10.34      1.02\n",
      " alpha[221,2]     -2.71      4.02     -2.46     -9.62      3.49     15.73      1.01\n",
      " alpha[221,3]    -26.33     29.37    -19.67    -69.38     11.11    216.72      1.00\n",
      " alpha[222,0]      0.36      5.85      0.55     -7.80     10.99     42.11      1.03\n",
      " alpha[222,1]      0.76      3.34      0.42     -4.49      6.41     11.60      1.03\n",
      " alpha[222,2]     -2.89      4.01     -2.63     -9.48      3.12     13.21      1.01\n",
      " alpha[222,3]    -11.66     31.39     -7.52    -56.62     38.86    343.88      1.00\n",
      " alpha[223,0]      0.51      5.51      0.51     -7.64     10.17     42.98      1.02\n",
      " alpha[223,1]      0.83      3.29      0.55     -4.35      6.53      9.92      1.03\n",
      " alpha[223,2]     -2.72      3.87     -2.50     -9.15      3.24     14.70      1.00\n",
      " alpha[223,3]    -17.39     30.70    -13.32    -66.29     30.06    385.14      1.00\n",
      " alpha[224,0]      0.18      5.25      0.50     -7.91     10.12     30.38      1.04\n",
      " alpha[224,1]      0.84      3.26      0.53     -3.95      6.69     10.07      1.02\n",
      " alpha[224,2]     -2.82      3.95     -2.74     -9.44      3.18     14.27      1.00\n",
      " alpha[224,3]    -23.17     29.12    -18.33    -66.29     19.72    604.78      1.00\n",
      " alpha[225,0]      0.32      5.80      0.42     -9.57      9.83     37.52      1.03\n",
      " alpha[225,1]      0.63      3.29      0.38     -3.86      6.81     11.61      1.02\n",
      " alpha[225,2]     -2.68      3.95     -2.39     -9.01      3.28     14.15      1.01\n",
      " alpha[225,3]     45.62     25.06     41.39      9.54     85.48     58.96      1.01\n",
      " alpha[226,0]      0.26      5.28      0.33     -6.57     11.18     28.49      1.04\n",
      " alpha[226,1]      0.72      3.15      0.60     -4.54      5.57     10.24      1.03\n",
      " alpha[226,2]     -2.55      4.32     -2.28     -9.32      3.84     17.18      1.00\n",
      " alpha[226,3]     22.40     28.68     15.86    -15.72     68.16     99.77      1.04\n",
      " alpha[227,0]     -0.60      5.15     -0.04     -9.44      7.46     24.60      1.05\n",
      " alpha[227,1]      0.32      3.13      0.15     -4.28      5.72     15.44      1.01\n",
      " alpha[227,2]     -1.32      3.83     -1.50     -8.16      4.55     18.55      1.03\n",
      " alpha[227,3]    -41.02     25.16    -36.81    -79.74     -3.33    134.31      1.01\n",
      " alpha[228,0]      0.35      5.76      0.34     -7.84     10.13     31.48      1.04\n",
      " alpha[228,1]      0.70      3.21      0.43     -4.21      6.53     10.45      1.03\n",
      " alpha[228,2]     -3.00      4.23     -2.66     -9.75      3.66     14.65      1.00\n",
      " alpha[228,3]     43.99     25.06     39.28      7.71     79.23     72.47      1.00\n",
      " alpha[229,0]      2.30      4.88      1.39     -4.27     10.85     14.77      1.01\n",
      " alpha[229,1]      0.67      3.34      0.44     -4.34      6.47     11.30      1.03\n",
      " alpha[229,2]     -3.39      4.08     -3.03     -9.95      3.28     11.98      1.00\n",
      " alpha[229,3]    -27.50     30.73    -22.41    -74.91     16.67    414.64      1.00\n",
      " alpha[230,0]      0.21      5.49      0.38     -9.17      9.68     30.34      1.04\n",
      " alpha[230,1]      0.81      3.20      0.45     -3.55      6.74      9.81      1.03\n",
      " alpha[230,2]     -2.64      4.07     -2.29    -10.26      2.89     15.45      1.01\n",
      " alpha[230,3]    -27.11     29.70    -19.71    -72.15     12.45    182.07      1.01\n",
      " alpha[231,0]      0.52      5.50      0.44     -7.90      9.72     47.93      1.02\n",
      " alpha[231,1]      0.71      3.26      0.38     -3.81      7.10     11.35      1.02\n",
      " alpha[231,2]     -2.74      3.90     -2.47     -8.96      3.81     14.48      1.00\n",
      " alpha[231,3]    -18.87     29.88    -13.57    -61.74     27.79    399.85      1.00\n",
      " alpha[232,0]     -0.14      5.87      0.24     -9.61      9.53     40.87      1.04\n",
      " alpha[232,1]      0.72      3.31      0.38     -3.72      7.13     10.00      1.03\n",
      " alpha[232,2]     -2.72      3.91     -2.61     -9.20      3.43     13.20      1.00\n",
      " alpha[232,3]     26.73     28.82     20.26    -15.63     68.26    138.18      1.00\n",
      " alpha[233,0]      1.44      5.18      0.99     -5.79     11.28     21.22      1.03\n",
      " alpha[233,1]      0.72      3.34      0.45     -4.11      6.92     11.96      1.01\n",
      " alpha[233,2]     -2.94      3.99     -2.79     -9.70      3.07     13.79      1.01\n",
      " alpha[233,3]    -17.22     29.93    -13.42    -68.43     25.41    559.37      1.00\n",
      " alpha[234,0]     -1.01      4.72     -0.42     -8.14      6.89     26.92      1.04\n",
      " alpha[234,1]      0.75      3.30      0.34     -4.29      6.62     10.73      1.02\n",
      " alpha[234,2]     -2.03      3.68     -2.10     -8.38      3.61     17.08      1.01\n",
      " alpha[234,3]    -31.21     30.15    -22.68    -74.87     11.16    135.75      1.01\n",
      " alpha[235,0]      0.52      5.93      0.47     -7.35     10.96     41.45      1.03\n",
      " alpha[235,1]      0.74      3.30      0.45     -5.27      5.64     10.26      1.02\n",
      " alpha[235,2]     -2.65      4.08     -2.44     -9.42      3.11     19.03      1.00\n",
      " alpha[235,3]    -18.43     30.61    -13.07    -67.25     25.20    401.17      1.00\n",
      " alpha[236,0]      3.14      5.28      2.06     -4.93     11.73     14.06      1.00\n",
      " alpha[236,1]      0.48      3.02      0.40     -5.04      4.93     12.11      1.02\n",
      " alpha[236,2]     -3.19      3.95     -2.88     -9.47      2.98     12.83      1.00\n",
      " alpha[236,3]    -24.45     29.29    -17.74    -69.49     15.64    143.03      1.01\n",
      " alpha[237,0]      0.36      5.34      0.45     -8.06      9.44     29.73      1.03\n",
      " alpha[237,1]      0.63      3.35      0.29     -5.02      6.21     12.09      1.02\n",
      " alpha[237,2]     -2.60      3.90     -2.46     -8.79      3.76     16.00      1.00\n",
      " alpha[237,3]    -15.73     31.44    -11.29    -61.29     29.65    576.75      1.01\n",
      " alpha[238,0]      0.20      5.79      0.29     -9.53      9.32     31.28      1.04\n",
      " alpha[238,1]      0.69      3.24      0.45     -4.29      6.26     10.91      1.02\n",
      " alpha[238,2]     -2.92      4.10     -2.69     -9.03      3.77     13.47      1.00\n",
      " alpha[238,3]     40.86     26.07     37.28      1.62     82.78    267.55      1.00\n",
      " alpha[239,0]     -0.09      6.04      0.30     -9.02      9.90     33.91      1.04\n",
      " alpha[239,1]      0.71      3.23      0.40     -4.04      6.26     11.27      1.02\n",
      " alpha[239,2]     -2.52      3.86     -2.25     -9.26      3.30     16.16      1.01\n",
      " alpha[239,3]    -23.36     28.26    -18.09    -67.42     17.62    368.06      1.00\n",
      " alpha[240,0]      2.48      4.92      1.73     -4.04     10.77     14.20      1.01\n",
      " alpha[240,1]      0.44      3.09      0.17     -4.32      5.80     13.27      1.02\n",
      " alpha[240,2]     -2.64      3.91     -2.55     -8.93      3.77     14.92      1.01\n",
      " alpha[240,3]    -26.56     28.26    -21.42    -69.79     15.29    233.83      1.00\n",
      " alpha[241,0]      0.37      5.84      0.44     -8.68     10.29     28.77      1.04\n",
      " alpha[241,1]      0.79      3.26      0.61     -3.67      6.96      9.70      1.03\n",
      " alpha[241,2]     -2.73      4.09     -2.46     -9.38      3.99     18.21      1.00\n",
      " alpha[241,3]    -24.96     32.45    -19.43    -74.39     23.05    149.08      1.01\n",
      " alpha[242,0]      0.29      5.72      0.32     -9.05      9.66     27.31      1.04\n",
      " alpha[242,1]      0.82      3.32      0.52     -5.15      6.03     10.67      1.02\n",
      " alpha[242,2]     -2.83      3.91     -2.56     -9.86      2.66     15.27      1.00\n",
      " alpha[242,3]    -29.89     29.35    -23.24    -74.58     11.12    161.19      1.01\n",
      " alpha[243,0]      0.16      6.11      0.34     -8.20     10.17     31.72      1.04\n",
      " alpha[243,1]      0.65      3.25      0.44     -4.71      6.07     10.47      1.02\n",
      " alpha[243,2]     -3.16      4.09     -2.76     -9.94      3.05     12.29      1.00\n",
      " alpha[243,3]     50.31     27.19     44.39     10.42     91.81     36.96      1.03\n",
      " alpha[244,0]     -0.39      5.51     -0.00     -9.80      8.76     30.84      1.05\n",
      " alpha[244,1]      0.68      3.24      0.36     -4.04      6.44     10.57      1.02\n",
      " alpha[244,2]     -2.71      3.95     -2.33    -10.15      2.79     16.58      1.01\n",
      " alpha[244,3]     37.40     25.10     31.75      2.96     76.24     78.79      1.01\n",
      " alpha[245,0]      0.31      5.67      0.54     -8.33      9.69     35.68      1.03\n",
      " alpha[245,1]      0.64      3.25      0.37     -5.21      5.74     10.61      1.02\n",
      " alpha[245,2]     -2.73      3.91     -2.48     -8.48      3.74     15.45      1.00\n",
      " alpha[245,3]     26.51     27.26     21.19    -12.52     63.03    157.85      1.00\n",
      " alpha[246,0]      0.25      5.61      0.42     -7.99     10.89     36.23      1.04\n",
      " alpha[246,1]      0.64      3.22      0.39     -3.63      6.79     10.89      1.03\n",
      " alpha[246,2]     -2.71      4.12     -2.54     -9.74      3.46     14.84      1.01\n",
      " alpha[246,3]     33.78     25.23     28.83      0.11     72.03     73.51      1.01\n",
      " alpha[247,0]      0.96      5.36      0.86     -7.78      9.82     35.27      1.02\n",
      " alpha[247,1]      0.75      3.21      0.40     -4.22      6.41      9.98      1.03\n",
      " alpha[247,2]     -2.91      4.20     -2.72     -9.84      3.19     13.77      1.01\n",
      " alpha[247,3]    -21.09     30.05    -16.42    -68.32     23.67    419.95      1.00\n",
      " alpha[248,0]      0.04      5.80      0.14     -9.21      8.89     47.86      1.02\n",
      " alpha[248,1]      0.66      3.24      0.29     -3.58      6.91     10.49      1.03\n",
      " alpha[248,2]     -2.87      4.03     -2.55     -9.79      3.14     13.55      1.01\n",
      " alpha[248,3]     33.14     26.54     26.49     -1.15     71.04     74.61      1.02\n",
      " alpha[249,0]      1.76      5.07      1.18     -5.60     10.80     21.18      1.02\n",
      " alpha[249,1]      0.64      3.22      0.36     -4.40      5.90     10.96      1.02\n",
      " alpha[249,2]     -2.92      3.82     -2.78     -8.83      3.52     12.48      1.00\n",
      " alpha[249,3]    -28.48     27.89    -23.37    -73.39     13.74    287.85      1.00\n",
      " alpha[250,0]      0.17      5.65      0.44     -8.72      9.72     23.23      1.05\n",
      " alpha[250,1]      0.54      3.20      0.40     -4.53      5.79     12.72      1.02\n",
      " alpha[250,2]     -2.57      4.07     -2.31     -9.37      3.47     16.37      1.01\n",
      " alpha[250,3]    -19.62     33.46    -14.14    -69.59     29.03    164.57      1.01\n",
      " alpha[251,0]      0.31      5.65      0.45     -8.54     10.42     24.99      1.04\n",
      " alpha[251,1]      0.66      3.18      0.43     -4.05      6.41     10.21      1.03\n",
      " alpha[251,2]     -2.84      4.13     -2.57     -9.86      3.23     19.91      1.00\n",
      " alpha[251,3]     17.59     30.92     10.42    -24.92     61.77    150.30      1.01\n",
      " alpha[252,0]      1.68      5.22      0.99     -5.46     11.78     15.73      1.03\n",
      " alpha[252,1]      0.49      3.15      0.22     -4.13      6.35     12.74      1.01\n",
      " alpha[252,2]     -2.80      3.92     -2.49     -9.14      3.28     13.04      1.00\n",
      " alpha[252,3]    -22.86     29.61    -16.82    -69.97     19.33    273.43      1.01\n",
      " alpha[253,0]      0.23      5.46      0.38     -8.90      9.39     38.42      1.03\n",
      " alpha[253,1]      0.63      3.27      0.25     -4.45      6.51     11.93      1.02\n",
      " alpha[253,2]     -2.85      3.99     -2.68     -9.04      3.65     13.74      1.01\n",
      " alpha[253,3]     23.10     26.35     17.22    -12.59     64.14    108.23      1.00\n",
      " alpha[254,0]      0.11      5.57      0.11     -9.34      8.67     32.51      1.03\n",
      " alpha[254,1]      0.78      3.25      0.43     -4.11      6.38      9.55      1.03\n",
      " alpha[254,2]     -2.79      3.95     -2.73     -9.58      2.86     11.85      1.01\n",
      " alpha[254,3]    -18.82     28.86    -14.43    -61.36     27.21    713.69      1.00\n",
      " alpha[255,0]      1.02      5.47      0.89     -7.24     11.12     27.16      1.03\n",
      " alpha[255,1]      0.75      3.12      0.54     -3.44      6.64      9.21      1.03\n",
      " alpha[255,2]     -2.66      4.15     -2.43     -9.94      3.19     14.40      1.00\n",
      " alpha[255,3]    -28.11     29.63    -21.72    -73.81     12.38    174.88      1.00\n",
      " alpha[256,0]     -0.00      5.76      0.18     -8.82      9.57     35.04      1.04\n",
      " alpha[256,1]      0.67      3.33      0.39     -4.79      6.22     11.48      1.02\n",
      " alpha[256,2]     -2.79      4.15     -2.47     -9.90      2.84     16.09      1.00\n",
      " alpha[256,3]     33.32     25.52     27.89     -3.93     72.90     65.69      1.01\n",
      " alpha[257,0]      0.48      5.36      0.46     -8.55      9.79     50.40      1.02\n",
      " alpha[257,1]      0.75      3.23      0.47     -4.14      6.56     10.62      1.02\n",
      " alpha[257,2]     -2.66      4.27     -2.44     -9.02      4.49     20.60      1.01\n",
      " alpha[257,3]     40.72     27.49     34.19      1.52     81.68     61.04      1.03\n",
      " alpha[258,0]      0.40      5.71      0.57     -9.21      8.73     55.13      1.02\n",
      " alpha[258,1]      0.70      3.50      0.42     -4.66      6.81     12.75      1.01\n",
      " alpha[258,2]     -2.73      4.13     -2.61     -8.63      4.45     16.11      1.00\n",
      " alpha[258,3]     29.16     25.11     24.26     -5.04     67.45    244.64      1.01\n",
      " alpha[259,0]     -0.03      5.75      0.14     -9.62      8.97     29.06      1.04\n",
      " alpha[259,1]      0.70      3.15      0.33     -3.95      6.48     10.60      1.03\n",
      " alpha[259,2]     -2.53      4.07     -2.43     -8.85      4.02     19.04      1.01\n",
      " alpha[259,3]    -23.00     28.28    -19.64    -65.13     20.37    327.90      1.00\n",
      "\n",
      "Number of divergences: 6\n"
     ]
    }
   ],
   "source": [
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=260, D=17, C=4, I=80\n"
     ]
    }
   ],
   "source": [
    "# prepare data for Stan model\n",
    "N, D = X_train.shape\n",
    "C = int(y_train.max())\n",
    "I = ind.max()\n",
    "print(\"N=%d, D=%d, C=%d, I=%d\" % (N,D,C,I))\n",
    "data = {'N': N, 'D': D, 'C': C, 'I':I, 'ind':ind_train, 'X': X_train, 'y': y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Automatic Differentiation Variational Inference (ADVI) is an EXPERIMENTAL ALGORITHM.\n",
      "WARNING:pystan:ADVI samples may be found on the filesystem in the file `/tmp/tmp7he9r5n0/output.csv`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.7 s, sys: 32.7 ms, total: 7.74 s\n",
      "Wall time: 7.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit = sm.vb(data=data, iter=10000, algorithm=\"meanfield\", grad_samples=10, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the posterior distributions of some of the parameters of our model (you may have called these variables something else...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pystan_utils.vb_plot_variables(fit, \"mu_prior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pystan_utils.vb_plot_variables(fit, \"sigma_prior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the inferred posteriors to make predictions. Lets first use the \"pystan_utils\" package to extract the expected values of the posterior distribution of the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fitted parameters\n",
    "mu_prior = pystan_utils.vb_extract_variable(fit, \"mu_prior\", var_type=\"vector\")\n",
    "sigma_prior = pystan_utils.vb_extract_variable(fit, \"sigma_prior\", var_type=\"vector\")\n",
    "alpha = pystan_utils.vb_extract_variable(fit, \"alpha\", var_type=\"matrix\", dims=(C,I))\n",
    "beta = pystan_utils.vb_extract_variable(fit, \"beta\", var_type=\"matrix\", dims=(C,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using expected values of the parameters, we can make predictions for the testset. However, we need to account for the fact that we now have different bias parameters per-individual, and adapt the code for making predictions accordingly. Make sure that you understand the code below. As always, if something is not 100% clear, ask! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyro\n",
    "alpha_mean = mcmc.get_samples()[\"alpha_mean\"]\n",
    "alpha_std  = mcmc.get_samples()[\"alpha_std\"]\n",
    "beta = mcmc.get_samples()[\"beta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test set, this needs to be modified. I don't understand why is it in this way.\n",
    "y_hat = alpha[:,ind_test-1] + np.dot(beta, X_test.T)\n",
    "y_hat = np.argmax(y_hat, axis=0) + 1\n",
    "print(\"predictions:\", y_hat)\n",
    "print(\"true values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [2 2 4 4 4 2 1 4 4 4 4 4 1 2 2 1 4 2 1 2 4 3 4 4 2 4 2 1 1 2 4 4 4 2 3 1 1\n",
      " 3 2 4 4 2 2 2 4 1 1 3 2 3 1 2 4 1 1 4 2 4 4 1 3 4 4 2 4 1 4 3 2 1 2 4 2 4\n",
      " 4 4 1 4 4 2 4 4 1 4 3 2 4 4 1 4 3 1 1 2 1 4 4 1 4 1 1 4 2 4 3 2 4 4 2 1 4\n",
      " 2 3 1 3 1 1 4 3 2 3 1 4 2 1 2 2 2 2 1 1 1 4 4]\n",
      "true values: [4 2 2 4 4 2 1 2 4 4 4 4 1 2 2 1 3 4 1 2 4 3 1 4 2 4 2 1 3 2 4 4 4 4 2 1 1\n",
      " 3 2 1 4 2 2 2 4 1 1 3 2 3 1 2 4 4 1 4 2 4 4 3 3 4 4 4 4 1 1 3 2 1 2 4 2 4\n",
      " 4 4 1 2 4 2 4 4 1 4 3 1 4 4 1 4 3 1 1 2 4 4 4 4 4 1 4 3 3 1 3 2 4 4 4 1 4\n",
      " 4 4 1 4 1 1 4 3 2 1 1 4 2 4 1 2 4 2 1 1 1 4 4]\n",
      "Accuracy: 0.7761194029850746\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test set\n",
    "y_hat = alpha[:,ind_test-1] + np.dot(beta, X_test.T)\n",
    "y_hat = np.argmax(y_hat, axis=0) + 1\n",
    "print(\"predictions:\", y_hat)\n",
    "print(\"true values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that is a signficant improvement, right? We improved the accuracy of our model from 67.9% to about 78.4%! (Hopefully you were able to obtain a similar or even better result :-)\n",
    "\n",
    "Did you see how your prior knowledge about the problem can make a substantial difference when building a model for it? This is how things are done in the model-based machine learning approach!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the posterior distributions inferred by STAN, we can even analyse the biases of different individuals identified by our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.49493799 -0.66547827 -0.97909644  6.05136226]\n",
      "1 [ 0.61548592 -0.1719418  -1.14377243  1.6775185 ]\n",
      "2 [ 0.63544016 -0.46592926 -1.11443979  0.05859614]\n",
      "3 [ 0.64697984  0.06464827 -1.15973146 -1.10694327]\n",
      "4 [ 0.47826976 -0.9520224  -0.42672376  0.06114656]\n",
      "5 [ 0.46148417 -0.51199502 -0.63216466  0.44860399]\n",
      "6 [ 0.18555415 -0.487783   -0.27201526  2.64464214]\n",
      "7 [ 0.34290118 -0.23219908 -0.64914334  0.02655454]\n",
      "8 [ 0.53397228 -0.16298139 -0.99478472  0.20757976]\n",
      "9 [ 0.53292804 -0.6945954  -1.02637797  6.7351566 ]\n",
      "10 [ 0.75264995 -0.00708048 -1.2262439  -2.05968167]\n",
      "11 [ 0.41021327  0.17589682 -0.93222552  1.10107654]\n",
      "12 [ 0.27819668  0.74573304 -1.03130682  4.17635658]\n",
      "13 [ 0.488279    0.09071233 -0.97708368 -0.05367024]\n",
      "14 [ 0.5005849   0.0158236  -1.11614501  1.65897884]\n",
      "15 [ 0.37439161 -0.20181668 -1.03104198  4.52107869]\n",
      "16 [ 0.52693513  0.07955342 -0.99318259 -0.1993491 ]\n",
      "17 [ 0.45045254 -0.2883676  -0.94003193  3.4269296 ]\n",
      "18 [ 0.40943727  0.41636781 -1.08654683  1.26800941]\n",
      "19 [ 0.34778718 -0.67983184 -0.61085821  5.67809145]\n",
      "20 [ 0.47023605 -0.22937602 -0.9354559   2.30025172]\n",
      "21 [ 0.58697478 -0.14124174 -1.01079174  0.12715045]\n",
      "22 [ 0.40181878  0.02982349 -0.67405016 -1.64290755]\n",
      "23 [ 0.41100988  0.10939722 -1.01197776  2.49609115]\n",
      "24 [ 0.47318727 -0.45711491 -0.99425732  5.24212686]\n",
      "25 [ 0.57993076 -0.09233204 -1.02973888 -0.51496473]\n",
      "26 [ 0.72708755 -0.4072512  -1.20503714  0.74032183]\n",
      "27 [ 0.40013314  0.10908236 -0.98723816  2.37273233]\n",
      "28 [ 0.57100221 -1.19769437 -1.08750905 13.52125831]\n",
      "29 [ 0.34717945 -0.21467739 -0.47266147 -0.78028749]\n",
      "30 [ 0.48476795  0.64910108 -1.50742345  6.06047773]\n",
      "31 [ 0.44748426 -0.43635461 -1.01318434  4.3902986 ]\n",
      "32 [ 0.73777483 -0.37256518 -1.10531545 -1.65125595]\n",
      "33 [ 0.53215919 -0.22798901 -0.9166043   2.04074411]\n",
      "34 [ 0.47641084 -0.20554603 -0.96375672  1.54986203]\n",
      "35 [ 0.58896135 -0.16479591 -0.98811738 -0.16274257]\n",
      "36 [ 0.49877862  0.4195881  -1.0152701   0.88883605]\n",
      "37 [ 0.56941782 -0.08888594 -1.04654632  0.00108909]\n",
      "38 [ 0.41580367 -0.19125627 -1.27382556 12.34870628]\n",
      "39 [ 0.45643221 -0.47917044 -0.83635197  2.47017489]\n",
      "40 [ 0.78800605 -0.51666286 -1.15432914 -2.53161375]\n",
      "41 [ 0.84113513 -0.74654638 -1.08864644 -1.26526257]\n",
      "42 [ 0.50208399 -0.3684978  -0.96211026  5.26287194]\n",
      "43 [ 0.29306674 -0.23963194 -0.96728444  8.7943557 ]\n",
      "44 [ 0.71674198 -0.5127007  -1.01267491 -1.08496812]\n",
      "45 [ 0.47661637 -0.12999047 -0.97285722  1.08140408]\n",
      "46 [ 0.43239116 -0.1660532  -0.72174882  0.6797629 ]\n",
      "47 [ 0.44932811 -0.90032365 -0.96388421  8.34477417]\n",
      "48 [ 0.34799413 -0.63221652 -0.92522495 10.10833184]\n",
      "49 [ 0.4408097   0.58151697 -1.01565987 -0.79452006]\n",
      "50 [ 0.47203921  0.2363478  -0.99502102 -0.57354614]\n",
      "51 [ 0.70857107 -0.32422334 -1.13436078 -1.36349632]\n",
      "52 [ 0.47644517 -0.59337436 -0.93610178  7.01917787]\n",
      "53 [ 0.36353833 -0.06380341 -0.51338219 -3.19728822]\n",
      "54 [ 0.34275378 -0.96516463 -0.98858554 12.52343167]\n",
      "55 [ 0.41937567 -0.38992945 -0.96926589  5.11567573]\n",
      "56 [ 0.45383508 -0.17905663 -0.99602052  5.24478363]\n",
      "57 [ 0.51379215  0.34043475 -0.99084138 -0.92391148]\n",
      "58 [ 0.3475523   1.44984639 -1.20915376 -3.47112244]\n",
      "59 [ 0.30068328 -0.59295288 -0.98673022 12.49009767]\n",
      "60 [ 0.52383048  0.16057926 -0.94172033 -1.53126852]\n",
      "61 [ 0.6028113  -0.16505617 -1.0191449  -0.60294118]\n",
      "62 [ 0.47209549 -0.05561028 -0.88587996  0.90325041]\n",
      "63 [ 0.64544761  0.08302231 -1.28756779  3.32514072]\n",
      "64 [ 0.56623982 -0.16981983 -1.05135393  1.26008756]\n",
      "65 [ 0.46180723 -0.3021308  -0.97230351  5.18136251]\n",
      "66 [ 0.49574184 -1.35864073 -0.95575741 13.07267419]\n",
      "67 [ 0.31457933  0.99613557 -1.10868988  0.45069636]\n",
      "68 [ 0.72309776 -0.41698492 -1.1243249  -0.38286467]\n",
      "69 [ 0.53014721 -0.5225391  -0.88848139  3.80310142]\n",
      "70 [ 0.39915115 -0.53479943 -1.07476003 10.83827431]\n",
      "71 [ 0.54565586  0.10584184 -0.97444494 -0.30411456]\n",
      "72 [ 0.27630371  0.83364456 -0.86658687 -0.90219667]\n",
      "73 [ 0.71911358 -0.79705902 -1.11462827  1.97453774]\n",
      "74 [ 0.39699592  0.34384516 -1.19544075  4.02676392]\n",
      "75 [ 0.22844086 -0.20799825 -0.23765813 -1.57864386]\n",
      "76 [ 0.58102817 -0.46198635 -1.06169403  2.17337855]\n",
      "77 [ 0.54795545 -0.29639075 -0.92612925  2.52589862]\n",
      "78 [ 0.61905801 -0.24879815 -1.06494369 -1.19040756]\n",
      "79 [ 0.65747089 -0.27268745 -1.02997994  0.2027687 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(I):\n",
    "    print(i, alpha[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps a histogram allows for a better global analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of biases towards mode 4 (car)\n",
    "plt.hist(alpha[3,:])\n",
    "plt.title(\"Biases towards mode 4\")\n",
    "plt.xlabel(\"alpha[4]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that, for most individuals the biases is around 0. However, we can also see that a few individuals really love their cars!\n",
    "\n",
    "Reflection exercise: can you think of ways in which you could use this model to try to identify policies (e.g. price changes or making terminals more efficient) that would allow to shift people's travel mode choices away from the car (e.g. towards public transport)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
